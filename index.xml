<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ArgsNo&#39;s Notes on ArgsNo&#39;s Notes</title>
    <link>https://argsno.github.io/</link>
    <description>Recent content in ArgsNo&#39;s Notes on ArgsNo&#39;s Notes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 23 Apr 2019 15:17:12 +0800</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>树的遍历</title>
      <link>https://argsno.github.io/2019/tree-traverse/</link>
      <pubDate>Tue, 23 Apr 2019 15:17:12 +0800</pubDate>
      
      <guid>https://argsno.github.io/2019/tree-traverse/</guid>
      <description>

&lt;p&gt;二叉树的遍历（特别是二查查找树）是数据结构与算法的基础知识，主要的遍历算法有四种，包括了先序遍历、中序遍历、后序遍历，还有层序遍历。不同的遍历算法流程经常会搞混了，特别是面试的时候。这里进行总结一下。&lt;/p&gt;

&lt;h2 id=&#34;前序遍历-pre-order-traversal&#34;&gt;前序遍历(Pre-Order Traversal)&lt;/h2&gt;

&lt;p&gt;指先访问根，然后访问子树的遍历方式。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void pre_order_traversal(TreeNode *root) {
    // Do Something with root
    if (root-&amp;gt;lchild != NULL)
        pre_order_traversal(root-&amp;gt;lchild);
    if (root-&amp;gt;rchild != NULL)
        pre_order_traversal(root-&amp;gt;rchild);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;中序遍历-in-order-traversal&#34;&gt;中序遍历(In-Order Traversal)&lt;/h2&gt;

&lt;p&gt;指先访问左（右）子树，然后访问根，最后访问右（左）子树的遍历方式&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void in_order_traversal(TreeNode *root) {
    if (root-&amp;gt;lchild != NULL)
        in_order_traversal(root-&amp;gt;lchild);
    // Do Something with root
    if (root-&amp;gt;rchild != NULL)
        in_order_traversal(root-&amp;gt;rchild);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;后序遍历-post-order-traversal&#34;&gt;后序遍历(Post-Order Traversal)&lt;/h2&gt;

&lt;p&gt;指先访问子树，然后访问根的遍历方式&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void post_order_traversal(TreeNode *root) {
    if (root-&amp;gt;lchild != NULL)
        post_order_traversal(root-&amp;gt;lchild);
    if (root-&amp;gt;rchild != NULL)
        post_order_traversal(root-&amp;gt;rchild);
    // Do Something with root
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;层次遍历&#34;&gt;层次遍历&lt;/h2&gt;

&lt;p&gt;层次遍历又称为二叉树的广度优先遍历，会先访问离根节点最近的节点，一层一层往下遍历。算法借助队列实现。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void Layer_Traver(tree *root) {
    int head = 0, tail = 0;
    tree *p[SIZE] = {NULL};
    tree *tmp;
    if (root != NULL) {
        p[head] = root;
        tail++;
        // Do Something with p[head]
    } else
        return;
    while (head &amp;lt; tail) {
        tmp = p[head];
        // Do Something with p[head]
        if (tmp-&amp;gt;left != NULL) { // left
            p[tail] = tmp-&amp;gt;left;
            tail++;
        }
        if (tmp-&amp;gt;right != NULL) { // right
            p[tail] = tmp-&amp;gt;right;
            tail++;
        }
        head++;
    }
    return;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;深度优先遍历&#34;&gt;深度优先遍历&lt;/h2&gt;

&lt;p&gt;先访问根结点，后选择一子结点访问并访问该节点的子结点，持续深入后再依序访问其他子树，可以轻易用递回或栈的方式实现。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void travel(treenode* nd){
    for(treenode* nex :　nd-&amp;gt;childs){ // childs 存放指向其每個子結點的指標
        travel(nex);   
    }
    return;
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>现代化的缓存设计方案</title>
      <link>https://argsno.github.io/2019/design-of-a-modern-cachepart-deux/</link>
      <pubDate>Tue, 26 Mar 2019 17:18:41 +0800</pubDate>
      
      <guid>https://argsno.github.io/2019/design-of-a-modern-cachepart-deux/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;原文地址：&lt;a href=&#34;http://highscalability.com/blog/2019/2/25/design-of-a-modern-cachepart-deux.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Design Of A Modern Cache—Part Deux&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在之前的&lt;a href=&#34;http://highscalability.com/blog/2016/1/25/design-of-a-modern-cache.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;文章&lt;/a&gt;里，主要介绍了&lt;a href=&#34;https://github.com/ben-manes/caffeine&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Caffeine&lt;/a&gt;使用的缓存算法，特别是其中的驱逐策略以及并发模型。自从上次文章发布之后，我们又对驱逐算法进行了更新并探索了另一种过期的机制。&lt;/p&gt;

&lt;h2 id=&#34;驱逐策略&#34;&gt;驱逐策略&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://dl.acm.org/citation.cfm?id=3149371&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Window TinyLFU&lt;/a&gt; (W-TinyLFU)&lt;/p&gt;

&lt;h2 id=&#34;过期机制&#34;&gt;过期机制&lt;/h2&gt;

&lt;p&gt;由于之前对于过期更高级的支持尚处于开发中，因此仅仅只是简要的提及。典型的做法要么是使用一个O(lg n)的优先级队列维持有序顺序，要么是将无用的条目保存在缓存中，并依赖于缓存的最大大小策略来最终驱逐出去。Caffeine仅仅使用平摊时间O(1)的算法，&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>写日志的那些事儿</title>
      <link>https://argsno.github.io/2019/%E5%86%99%E6%97%A5%E5%BF%97%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/</link>
      <pubDate>Mon, 04 Feb 2019 15:15:08 +0800</pubDate>
      
      <guid>https://argsno.github.io/2019/%E5%86%99%E6%97%A5%E5%BF%97%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/</guid>
      <description>

&lt;h2 id=&#34;写日志简介&#34;&gt;写日志简介&lt;/h2&gt;

&lt;p&gt;一般提到写日志，主要有下面几种不同的场景：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;诊断日志：应用打印异常信息，排查问题用，一般是给人看的，输出格式会比较随意，里面可能会有异常堆栈，或者排查问题用的一些文本信息；&lt;/li&gt;
&lt;li&gt;数据日志：一般是用来做监控和数据分析的，可以人肉临时分析，也可以给机器分析，要求格式比较固定；&lt;/li&gt;
&lt;li&gt;交易日志：一般在日志式文件系统、NoSQL、DB 中使用，一般有 &lt;a href=&#34;http://en.wikipedia.org/wiki/Journaling_file_system&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;journaling&lt;/a&gt;，WAL（&lt;a href=&#34;http://en.wikipedia.org/wiki/Write-ahead_logging&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;write-ahead logging&lt;/a&gt;），binlog。这种日志通常都不是给人看的。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;EagleEye 写的日志，是数据日志，记录的是中间件的网络调用埋点，或者是应用的业务埋点，它们都通过调用 eagleeye-core 的 EagleEye API 输出。
EagleEye 在写日志方面，有下面几个目标：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;写日志性能要足够好，应避免影响应用主流程；&lt;/li&gt;
&lt;li&gt;写日志对系统影响尽量小，在系统压力很大的时候，甚至可以选择放弃输出日志。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在最老的实现里，EagleEye 使用了常见的 log4j 去写日志，在 1.1.3 版的大幅重构之后，就自己直接实现了写日志。
当时想法就是要简化写日志的逻辑，因为 EagleEye 并不是通用的写日志组件，而是写自己的埋点日志。不使用通用的日志框架，主要考虑有几点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;自己写，可控性强，可以做专门定制化，有利于提升性能&lt;/li&gt;
&lt;li&gt;避免日志组件的依赖冲突问题，不用再担心 Classloader 隔离、类加载等&lt;/li&gt;
&lt;li&gt;可以把很多 EagleEye 不需要的通用逻辑砍掉，例如配置化、日志级别（LogLevel）、日志格式（Layout）、层次结构（Category）、多种输出实现（Appender）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;从写日志这个功能上面讲，可以细分成三步：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;写日志到 logger：指调用 log(&amp;hellip;) 方法，把字符串和相关参数传到日志框架。对于框架来说，这是一个追加日志的事件（LogEvent）。&lt;/li&gt;
&lt;li&gt;把日志编码成字符串或字节：指把日志事件格式化，编码成字符串或字节数组的过程，例如每行日志按照指定格式追加时间戳、日志级别、代码位置等信息，就是在这一步完成。&lt;/li&gt;
&lt;li&gt;日志输出到目的地：通用日志框架可以指定多个输出目的地（Appender），目的地不仅可以是写本地文件，甚至可以是走网络、存数据库、发消息等。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面就这三步，结合 EagleEye 关注的目标，说说在这些方面遇到了什么问题，以及如何实现的。&lt;/p&gt;

&lt;h2 id=&#34;写日志到-logger&#34;&gt;写日志到 logger&lt;/h2&gt;

&lt;h3 id=&#34;同步写的问题&#34;&gt;同步写的问题&lt;/h3&gt;

&lt;p&gt;多线程环境并发写日志，首先需要保证线程安全，就是说，多个线程一起写日志时，内容不能出现交织。
要做到这一点，最最简单的办法，就是每条线程单独写一个文件，这个方案在淘宝是不现实的，因为应用的线程非常多（仅 HSF 线程池就已经有 600 个线程），如果采用这个方案，会产生很多日志文件。
再简单一点的办法是把写日志作为临界区，进入临界区时用锁来保证每一时刻只有一个线程在写日志，例如 BufferedOutputStream 就是一个写时同步的实现。
应用用 log4j、logback 打日志，如果没特殊配置过，一般就是同步写的。&lt;/p&gt;

&lt;p&gt;EagleEye 的 1.1.x 版自己实现写日志，用的就是同步写的方案。使用同步写一般是很快的，但是极偶尔会出现写日志写 hang 住的情况，这时候会把当前正在写日志的线程卡住，其它要写日志的线程就会堵塞在临界区外面等待。
EagleEye 1.1.x 版上线后，遇到过好几次应用的 HSF 线程池里几乎全部线程都卡在写 EagleEye 日志上的情况，导致这台服务器的服务有一段时间基本不可用。出现写硬盘 hang 住的情况虽然不多见，但是起因很难排查，对于 EagleEye 这种网络调用埋点，一旦卡住，就会导致这次调用超时。如果是业务线程写日志 hang 住，就会导致业务请求处理超时。（所以应用使用同步去写日志，都会有因为写日志导致响应超时的风险。）&lt;/p&gt;

&lt;h3 id=&#34;异步写-基于-blockingqueue&#34;&gt;异步写，基于 BlockingQueue&lt;/h3&gt;

&lt;p&gt;在 1.2.x 之后，改用了异步写的方案：任何线程要写日志，只需要把日志事件对象加入日志队列就行了，后台会专门起一个线程从队列取日志、写文件。
这是一个典型的多生产者对单消费者的问题，关键就在于这个队列的实现，因为这里面涉及消费者等待队列不空，生产者等待队列空的逻辑，当时就选择了比较直观的 BlockingQueue。
j.u.c 里比较常见的 BlockingQueue 实现，有 ArrayBlockingQueue、LinkedBlockingQueue、LinkedTransferQueue、SynchronousQueue 这几个：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;SynchronousQueue 常用于生产者消费者一对一交换的场景，不适合。&lt;/li&gt;
&lt;li&gt;LinkedTransferQueue 是 Java7 里新加的队列实现，在 NIO 框架、线程池框架里常亮相，性能应该不错，不过提交日志到队列，完全不需要等待消费者做 transfer 动作，因此用不上。&lt;/li&gt;
&lt;li&gt;LinkedBlockingQueue 是基于链表实现的队列，一头一尾各有一把锁，缺点就是入队有内存分配开销。&lt;/li&gt;
&lt;li&gt;ArrayBlockingQueue 是一个定长的环形数组，队列创建之后，就没有内存开销了，但缺点是这个队列共用一把锁，竞争比 LinkedBlockingQueue 激烈。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;实测发现用 LinkedBlockingQueue 做队列，吞吐量比 ArrayBlockingQueue 高，但考虑到 ArrayBlockingQueue 本身的定长特性，在写日志 qps 很高时内存波动更稳定，而且队列定长也正好可以作为写日志的“节流阀”（队列满时，新增的日志无法放入，会直接被丢弃，从而起到控制日志写入速度的作用），因此最终选择了 ArrayBlockingQueue。
log4j、logback 等日志框架，有对应的 AsyncAppender 实现异步队列，都选择了 ArrayBlockingQueue。&lt;/p&gt;

&lt;p&gt;使用 BlockingQueue 入队有一个细节，就是用 add、put、offer 中的哪一个。add 会抛异常是不合适的，关键还是看 put 还是 offer。put 是一直等，直到入队为止，offer 是不等，或者只尝试等一段时间。相比之下，offer 的实现更合适，对于调用埋点日志，如果队列满，可以直接把日志丢掉不用等；对于更重要一些的业务日志，尽量不丢弃，可以尝试等几百毫秒。如果使用了等的策略，日志队列又经常满的话，会拖慢业务的响应时间，logback 用了 put 来保证重要日志不丢失，在高 qps 时，吞吐量是比用 offer 要差的。&lt;/p&gt;

&lt;p&gt;改造之后，20 线程 4w qps 记一条 EagleEye 日志平均耗时是 2500ns 左右。&lt;/p&gt;

&lt;h3 id=&#34;异步写-基于无锁队列&#34;&gt;异步写，基于无锁队列&lt;/h3&gt;

&lt;p&gt;1.2.0、1.2.1 上线以后，发现写日志 qps 在 2000 以上时，系统的上下文切换也会相应增高 3000-4000 次。ArrayBlockingQueue 本身锁争用比较高，而且生产者每把一条日志加入队列后，都会唤醒消费者去消费，这是 BlockingQueue 的实现要求。在日志队列这个场景，消费者的速度一般高于生产者速度，因此队列经常处于空状态，消费者每次起来只处理一条或几条日志之后队列又空了只好重新挂起等待，而生产者每放入一条日志，都会唤醒消费者，结果就会导致系统 cs 偏高。&lt;/p&gt;

&lt;p&gt;如果把 BlockingQueue 的功能拆开来看，一个功能是在维护队列在并发场景的出队、入队，另一个功能是做生产者、消费者之间的同步策略。
前一个功能可以另外用无锁队列来实现，降低锁争用开销，后一个功能可以针对记日志的场景做专门优化。&lt;/p&gt;

&lt;p&gt;j.u.c 里面的 ConcurrentLinkedQueue 就是默认的无锁队列。另外，&lt;a href=&#34;http://www.cs.tau.ac.il/~shanir/nir-pubs-web/Papers/FIFO_Queues.pdf&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;这篇论文&lt;/a&gt;也提出了一个对无锁队列的改进。不过，这些实现都是在无界队列上实施的算法，更适合的数据结构应该是对 ArrayBlockingQueue 的定长环形数组进行改造，把它变为无锁。看到这里，相信有不少同学能想到最近比较火的 &lt;a href=&#34;http://lmax-exchange.github.io/disruptor/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Disruptor&lt;/a&gt;，这个库的核心就是使用环形数组（RingBuffer）实现无锁队列，性能号称比 ArrayBlockingQueue 要好不少。&lt;/p&gt;

&lt;p&gt;EagleEye 记日志的场景对异步队列的需求可以简化成多生产者对单消费者的需求，因此专门写一个无锁队列去做这件事比较合适。在写这个无锁队列时，主要参考了 Disruptor 的 RingBuffer 实现，另外，&lt;a href=&#34;http://psy-lob-saw.blogspot.com/2013/03/single-producerconsumer-lock-free-queue.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;这篇博客&lt;/a&gt;提出了不少对环形数组实现的无锁队列的优化方法也很有参考价值。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://tbdocs.alibaba-inc.com/download/attachments/200202264/ringBuffer.png?version=1&amp;amp;modificationDate=1371367699000&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;上面的三幅图简单说明了这个最大长度为 qsize 的环形队列实现，即由 put、take 两个游标来标识当前队列的&lt;strong&gt;下一次&lt;/strong&gt;调用 put 和 take 应该返回的位置，put、take 是 &lt;strong&gt;64位长的递增的非负数&lt;/strong&gt;，队列需要时刻保证 put&amp;gt;= take 且 (put - take) &amp;lt;= qsize。队列的长度为：(put - take)，判空方法是 put == take，判满的方法是 (put - take) == qsize。元素入队时，需要判断是否队满，然后 CAS 设置 put 自增即可；出队时，先判断是否队空。具体代码不多，这里也不细说了，有兴趣的同学可以直接看 eagleeye-core 里面的 AsyncAppender 实现。&lt;/p&gt;

&lt;p&gt;在这里简单提一下几个注意点：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;ABA 问题：因为 put、take 是 &lt;strong&gt;64位长的递增的非负数&lt;/strong&gt;，所以每次返回的元素下标唯一，从而避免了 CAS 算法的 ABA 问题。&lt;/li&gt;
&lt;li&gt;使用位操作来计算数组下标：要求队列的最大长度是 2 的 n 次方，那么计算 x 在队列中的数组下标可以用 (x &amp;amp; (qsize - 1)) 来取代 (x % qsize)。&lt;/li&gt;
&lt;li&gt;消费者批量消费：由于只有一个消费者，那么它在判断队列是否为空时，可以得到队列当前的 size，那么它可以一口气消费 size 个元素。&lt;/li&gt;
&lt;li&gt;避免伪共享：把队列用到的 Long、AtomicLong 补齐成 64 个字节，把整个 CacheLine 填满。&lt;/li&gt;
&lt;li&gt;降低内存屏障的开销：如果临时读到旧数据不会带来特别大的问题，可以使用 AtomicLong.lazySet(value) 来取代 volatile 的写。另外，可以把读到的 volatile 变量值缓存在一个非 volatile 变量中，判断时先读非 volatile 变量，减少读 volatile 变量的开销。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;另外再谈谈生产者和消费者之间的同步策略。Disruptor 把这个抽象为 WaitStrategy，提供了忙等（BusySpin）、阻塞等（Blocking）、睡眠等（Sleeping）、弃权等（Yielding）等等多种实现，比 BlockingQueue 要灵活很多。写日志这里，比较适合的方式应该是阻塞等和睡眠等。睡眠等的策略要求队列容量比较大，否则很容易在生产速度很快的时候，出现因为写满队列了消费者还没醒来，导致丢日志的情况。阻塞等的策略要针对写日志做调整，否则就出现 ArrayBlockingQueue 那种频繁唤醒消费者导致上下文切换频繁的问题了。EagleEye 把生产者唤醒消费者的条件改为：在队列的日志数超过指定阈值（队列快满了），且消费者不在运行状态，且生产者可以获得锁，才唤醒消费者。为了避免写日志 qps 非常低时，要很长时间才到达阈值的问题，消费者的阻塞要设置最大时间为 1 秒，这样，无论如何 1 秒内写的日志肯定会被处理的。&lt;/p&gt;

&lt;p&gt;改造之后，20 线程 4w qps 记一条 EagleEye 日志平均耗时是 1500ns 左右。&lt;/p&gt;

&lt;h3 id=&#34;获取当前时间&#34;&gt;获取当前时间&lt;/h3&gt;

&lt;p&gt;EagleEye 埋点每条都有时间戳，对于多阶段的网络调用，还会统计到每个阶段的耗时，每次免不了都要获取一次时间。那么是否需要对 System.currentTimeMillis() 进行优化呢？如果需要优化，可以由后台线程每毫秒更新一次一个本地的时间戳变量，需要读取时间时，直接读取本地的这个时间戳。EagleEye 当前还没做这个处理，因为获取时间的实现是调用 gettimeofday()，在 64 位 Linux 并不是系统调用，开销非常小。&lt;/p&gt;

&lt;p&gt;写日志跟时间相关的，还有另一个注意点，就是不同时区的服务器时间应该做调整，调整成统一的时区。例如美国服务器调用在东八区的中国服务器，记录的日志时间会不一样，这对分析是一个麻烦。因此，可以在初始化时先把时区的时间差算好，记录时间时，统一调整到东八区。（这里记录的时间是形如：2013-02-03 12:34:56 这样的，而不是毫秒数，如果记录 System.currentTimeMillis()，已经统一为 UTC 时区了）&lt;/p&gt;

&lt;h2 id=&#34;把日志编码成字符串-字节&#34;&gt;把日志编码成字符串 / 字节&lt;/h2&gt;

&lt;p&gt;写日志的这一步，一般就是把日志对象 Encode 为字符串。有下面几个细节点：&lt;/p&gt;

&lt;h3 id=&#34;预先分配字符串的输出大-buffer&#34;&gt;预先分配字符串的输出大 buffer&lt;/h3&gt;

&lt;p&gt;不建议每输出一行都申请一次 buffer（例如每次都 new StringBuilder()），这样会增加对象分配和 GC 压力。可以在 ThreadLocal 放置一个 4KB 输出缓存，重复使用。因为 EagleEye 使用的异步队列能保证仅有一个线程做 encode，所以可以连 ThreadLocal 都省掉。&lt;/p&gt;

&lt;h3 id=&#34;减少-append-操作的越界检查&#34;&gt;减少 append 操作的越界检查&lt;/h3&gt;

&lt;p&gt;StringBuilder 的性能是挺好了，但是每次 append 都要做字符串越界检查，可以自己实现一个特殊的 StringBuilder，让它的 API 可以接受多个参数，让越界检查少做几次。或者不怕麻烦的话直接用 char[] 也是可以的。&lt;/p&gt;

&lt;h3 id=&#34;整数转字符串-浮点转字符串的优化&#34;&gt;整数转字符串、浮点转字符串的优化&lt;/h3&gt;

&lt;p&gt;EagleEye 没有用这种优化，&lt;a href=&#34;http://www.cppblog.com/Solstice/archive/2011/07/17/151224.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;这篇博文&lt;/a&gt;里提到了写日志可以用这种优化，有需要的同学可以试试。&lt;/p&gt;

&lt;h3 id=&#34;字符编码转换&#34;&gt;字符编码转换&lt;/h3&gt;

&lt;p&gt;由于历史原因，EagleEye 日志用的是 GBK 编码，如果输出用 UTF-8 编码，对于内码使用 Unicode 的 JVM 来说转换会更快（因为 Unicode 转 GBK 要查表，Unicode 转 UTF-8 只要算就行了）。UTF-8 也更加适合国际化。&lt;/p&gt;

&lt;h2 id=&#34;日志输出到目的地&#34;&gt;日志输出到目的地&lt;/h2&gt;

&lt;p&gt;EagleEye 现在只有输出到本地文件的功能，因此下面仅介绍这方面的一些经验。&lt;/p&gt;

&lt;h3 id=&#34;使用-buffer-输出&#34;&gt;使用 buffer 输出&lt;/h3&gt;

&lt;p&gt;使用 buffer 写文件，对写性能有很大提高，一般可以把 buffer 设置成 8KB 输出。如果不使用 buffer，或者 buffer 比较小，那么写日志到硬盘的次数会增大不少，IOPS 高了对系统有影响。毕玄给的建议是写日志有 500 IOPS 对于虚拟机来说已经有点吃力啦。实测发现 EagleEye 按 4w qps 写日志48KB 缓存每条日志 100 字节，写硬盘的次数基本在 500 左右。因此对日志写入次数做控制是有必要的。&lt;/p&gt;

&lt;p&gt;使用 buffer 这块，可以跟上面编码字符串用同一个缓存，这样编码后可以直接就输出了，节省一次拷贝。如果用 StringBuilder.toString()，它会拷贝出一个 String 返回，然后如果你把 String 放入输出 buffer 里面，又会再触发拷贝一次。所以说，buffer 最好自己能控制，JVM 里面的字符串多余拷贝还是比较多的，不知不觉性能就下去了。&lt;/p&gt;

&lt;h3 id=&#34;写文件的性能&#34;&gt;写文件的性能&lt;/h3&gt;

&lt;p&gt;目前 EagleEye 还是用的 FileOutputStream，最近看到 log4j 2 用的是 &lt;a href=&#34;http://logging.apache.org/log4j/2.x/manual/appenders.html#FastFileAppender&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;ByteBuffer + RandomAccessFile 的策略&lt;/a&gt;，号称性能提升 20～200%。后面可以看看实现，试一下效果。&lt;/p&gt;

&lt;h3 id=&#34;文件归档滚动时不要删除文件&#34;&gt;文件归档滚动时不要删除文件&lt;/h3&gt;

&lt;p&gt;Linux 系统删除一个大文件（超过 500MB）会比较慢，日志越大卡住的时间越长。因此，文件归档时应该尽量避免由写日志线程直接去删除文件，可以先把当前文件重命名，然后创建新文件去写。删除过期的归档文件可以让后台维护线程去做，或者用脚本去做清理。&lt;/p&gt;

&lt;h3 id=&#34;多进程写日志&#34;&gt;多进程写日志&lt;/h3&gt;

&lt;p&gt;上面谈的是多线程写日志，那么，多进程如何写日志才能避免日志内容交织呢？EagleEye 1.3.0 以后做了特殊处理，所以如果多进程写日志都写在同一个文件上，不会产生交织情况（log4j 也有这个问题）。多进程写日志的方案有下面几个：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;每个进程单独写一个文件。这个方案简单可靠，缺点是对日志收集来说有点不方便，但可以接受。&lt;/li&gt;
&lt;li&gt;写文件时，每个进程都先获取文件锁 FileChannel.lock()，写完之后 release。logback 用的是这个策略（prudent=true）。&lt;/li&gt;
&lt;li&gt;依赖 write(2) O_APPEND 的原子性：open(2)/write(2) 在设置了 O_APPEND 之后，操作系统可以保证写入是原子操作（一次写出的内容不要超过 PAGE_SIZE=4K），在&lt;a href=&#34;http://www.chinaunix.net/old_jh/23/829712.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;这里&lt;/a&gt;有详细讨论。JVM 里面，如果使用 new FileOutputStream(file, append) 这个 API，第二个参数 append 设置为 true，会带有 O_APPEND 参数。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这是 FileOutputStream 的代码，设置了 append 为 true，就会设置 O_APPEND。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;openjdk/jdk/src/solaris/native/java/io/FileOutputStream_md.c&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;JNIEXPORT void JNICALL
Java_java_io_FileOutputStream_open(JNIEnv *env, jobject this,
                                   jstring path, jboolean append) {
    fileOpen(env, this, path, fos_fd,
             O_WRONLY | O_CREAT | (append ? O_APPEND : O_TRUNC));
}
 
JNIEXPORT void JNICALL
Java_java_io_FileOutputStream_writeBytes(JNIEnv *env,
    jobject this, jbyteArray bytes, jint off, jint len, jboolean append) {
    writeBytes(env, this, bytes, off, len, append, fos_fd);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;openjdk/jdk/src/solaris/native/java/io/io_util_md.c&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void
writeBytes(JNIEnv *env, jobject this, jbyteArray bytes,
           jint off, jint len, jboolean append, jfieldID fid)
{
...
            if (append == JNI_TRUE) {
                n = (jint)IO_Append(fd, buf+off, len);
            } else {
                n = (jint)IO_Write(fd, buf+off, len);
            }
 
...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;openjdk/jdk/src/solaris/native/java/io/io_util_md.h&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#define IO_Append JVM_Write
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;openjdk/hotspot/src/share/vm/prims/jvm.cpp&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;JVM_LEAF(jint, JVM_Write(jint fd, char *buf, jint nbytes))
  JVMWrapper2(&amp;quot;JVM_Write (0x%x)&amp;quot;, fd);
 
  //%note jvm_r6
  return (jint)os::write(fd, buf, nbytes);
JVM_END
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到实际用的是 write(2) 系统调用：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;openjdk/hotspot/src/os/linux/vm/os_linux.inline.hpp&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;inline size_t os::write(int fd, const void *buf, unsigned int nBytes) {
  size_t res;
  RESTARTABLE((size_t) ::write(fd, buf, (size_t) nBytes), res);
  return res;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;关于 write(2) 在 O_APPEND 的原子性： &lt;a href=&#34;http://pubs.opengroup.org/onlinepubs/009695399/functions/pwrite.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;http://pubs.opengroup.org/onlinepubs/009695399/functions/pwrite.html&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If the O_APPEND flag of the file status flags is set, the file offset shall be set to the end of the file prior to each write and no intervening file modification operation shall occur between changing the file offset and the write operation.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;不过值得注意的是，write(2) 的写原子性和系统实现有关联，这是 POSIX 规范，不同的系统不一定会遵循。&lt;/p&gt;

&lt;h2 id=&#34;运维友好方面的细节&#34;&gt;运维友好方面的细节&lt;/h2&gt;

&lt;p&gt;下面是 EagleEye 在实现时遇到的一些很难归入上面三大类的问题，大家可以参考下。&lt;/p&gt;

&lt;h3 id=&#34;日志写到固定路径&#34;&gt;日志写到固定路径&lt;/h3&gt;

&lt;p&gt;EagleEye 日志都固定写到 ~/logs/eagleeye 目录下面，调用日志是 eagleeye.log，业务日志是 biz_eagleeye.log。使用统一的固定路径有一个好处，就是找起来方便，日志收集也很容易配置。现在淘宝的应用日志路径里面，有的会包含机器名、应用名，定位日志就要费周章了，而且，还要考虑机器名、应用名会改变的问题。如果这些变量追加在日志文件名上面，会相对好一些。&lt;/p&gt;

&lt;h3 id=&#34;自动删除存档文件&#34;&gt;自动删除存档文件&lt;/h3&gt;

&lt;p&gt;已经不止一次见到由于日志打爆硬盘导致 P1 故障了，所以删除历史存档这个功能尽量给程序自己做，指望部署脚本定时删除相对不靠谱，靠人肉删就更不靠谱了。&lt;/p&gt;

&lt;h3 id=&#34;文件按大小滚动&#34;&gt;文件按大小滚动&lt;/h3&gt;

&lt;p&gt;EagleEye 的日志是按文件大小滚动的，不采用按时间滚动，是因为 EagleEye 日志随这应用 qps 上升会线性翻倍，有可能会 1 小时就打出了大量日志。如果按大小滚动，那么 EagleEye 日志在硬盘的占用量是固定可控的。前面提到删除的文件越大就越慢，因此 EagleEye 日志一般 300MB 左右会滚动，保证删起来也比较快。&lt;/p&gt;

&lt;p&gt;另外注意，获取文件大小本身也是一个系统调用，会比较耗时，因此日志输出的实现应该把文件大小在内存中缓存计数，避免每次都调用系统方法去获取文件大小。&lt;/p&gt;

&lt;h3 id=&#34;运行时开关&#34;&gt;运行时开关&lt;/h3&gt;

&lt;p&gt;写日志组件应该提供运行时开关，可以方便控制日志级别。EagleEye 提供了文件级别的开关，可以运行时打开、关闭日志输出，调整日志的采样率（采样率是 EagleEye 自身的特性，一般日志框架不需要）。另外，为了大范围批量操作方便，还需要支持通过 diamond 上配置开关，这些功能 EagleEye 是依赖 HSF/Pandora 去完成的。&lt;/p&gt;

&lt;h3 id=&#34;运行期文件被删除了怎么办&#34;&gt;运行期文件被删除了怎么办&lt;/h3&gt;

&lt;p&gt;这是一般记日志的框架不会考虑的，但是确实会遇到。例如文件被误删，或者因为长时间没写日志，文件被清理脚本删掉了（Linux 可以删，但是进程还持有文件 fd，文件 inode 在进程 close 的时候才释放，还可以“正常”读写；对于 Windows，一般锁住删不掉，但是如果用 Unlocker 一类软件是可以解锁句柄的）。出现了这种情况，除非把应用重启，否则只能干瞪眼了。因此，EagleEye 在后台线程还会监视日志文件是否被删除，如果删除了就滚动日志，重建文件。&lt;/p&gt;

&lt;h3 id=&#34;日志的日志&#34;&gt;日志的日志&lt;/h3&gt;

&lt;p&gt;用来记录日志框架本身的一些异常信息，对排查问题有很大帮助。例如 log4j 的 LogLog。实现时需要注意记日志不要导致死循环。&lt;/p&gt;

&lt;h3 id=&#34;每秒刷新&#34;&gt;每秒刷新&lt;/h3&gt;

&lt;p&gt;EagleEye 为了提高性能，使用异步实现日志输出，输出 buffer 还带有 8KB 缓存，写满才会写文件，但是对于日常环境，或者线上排查问题的场景，会期望日志能马上刷出来。日志框架里一般都可以配置是否“immediateFlush”，但是这会比较影响性能。EagleEye 的做法是异步队列的消费者线程每 1 秒至少会醒一次，检查是否需要写日志，写完日志之后，还要触发本批日志刷新。当日志写到缓存 buffer 时，buffer 会检查距离上次写文件是否超过 1s，如果超过 1s，即使不满 4KB 也会触发刷新。&lt;/p&gt;

&lt;h3 id=&#34;应用退出时不丢日志&#34;&gt;应用退出时不丢日志&lt;/h3&gt;

&lt;p&gt;这是对每秒刷新的进一步补充，应用退出时把最后一秒还没写到文件的内容刷新出去，可以在 Runtime 上设置 ShutdownHook 实现。&lt;/p&gt;

&lt;h3 id=&#34;不依赖系统默认的字符编码&#34;&gt;不依赖系统默认的字符编码&lt;/h3&gt;

&lt;p&gt;EagleEye 的业务日志包含不少中文，如果字符串输出到文件时不指定编码，就会用系统的默认编码（String.getBytes() 或 new Writer() 时），不同编码的系统就产生不同编码的日志，会导致日志收集、后期分析处理出现乱码。因此需要为输出统一设置编码。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;本文转载自：&lt;a href=&#34;https://yq.aliyun.com/articles/2920&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;写日志的那些事儿&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>大众点评搜索基于知识图谱的深度学习排序实践</title>
      <link>https://argsno.github.io/2019/dianping-search-deeplearning/</link>
      <pubDate>Sat, 26 Jan 2019 23:03:32 +0800</pubDate>
      
      <guid>https://argsno.github.io/2019/dianping-search-deeplearning/</guid>
      <description>

&lt;h2 id=&#34;1-引言&#34;&gt;1. 引言&lt;/h2&gt;

&lt;h3 id=&#34;挑战与思路&#34;&gt;挑战与思路&lt;/h3&gt;

&lt;p&gt;搜索是大众点评App上用户进行信息查找的最大入口，是连接用户和信息的重要纽带。而用户搜索的方式和场景非常多样，并且由于对接业务种类多，流量差异大，为大众点评搜索（下文简称点评搜索）带来了巨大的挑战，具体体现在如下几个方面：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;意图多样&lt;/strong&gt;：用户查找的信息类型和方式多样。信息类型包括POI、榜单、UGC、攻略、达人等。以找店为例，查找方式包括按距离、按热度、按菜品和按地理位置等多种方式。例如用户按照品牌进行搜索时，大概率是需要寻找距离最近或者常去的某家分店；但用户搜索菜品时，会对菜品推荐人数更加敏感，而距离因素会弱化。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;业务多样&lt;/strong&gt;：不同业务之间，用户的使用频率、选择难度以及业务诉求均不一样。例如家装场景用户使用频次很低，行为非常稀疏，距离因素弱，并且选择周期可能会很长；而美食多为即时消费场景，用户行为数据多，距离敏感。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;用户类型多样&lt;/strong&gt;：不同的用户对价格、距离、口味以及偏好的类目之间差异很大；搜索需要能深度挖掘到用户的各种偏好，实现定制化的“千人千面”的搜索。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LBS的搜索&lt;/strong&gt;：相比电商和通用搜索，LBS的升维效应极大地增加了搜索场景的复杂性。例如对于旅游用户和常驻地用户来说，前者在搜索美食的时候可能会更加关心当地的知名特色商户，而对于距离相对不敏感。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;上述的各项特性，叠加上时间、空间、场景等维度，使得点评搜索面临比通用搜索引擎更加独特的挑战。而解决这些挑战的方法，就需要升级NLP（Natural Language Processing，自然语言处理）技术，进行深度查询理解以及深度评价分析，并依赖知识图谱技术和深度学习技术对搜索架构进行整体升级。在美团NLP中心以及大众点评搜索智能中心两个团队的紧密合作之下，经过短短半年时间，点评搜索核心KPI在高位基础上仍然大幅提升，是过去一年半涨幅的六倍之多，提前半年完成全年目标。&lt;/p&gt;

&lt;h3 id=&#34;基于知识图谱的搜索架构重塑&#34;&gt;基于知识图谱的搜索架构重塑&lt;/h3&gt;

&lt;p&gt;美团NLP中心正在构建全世界最大的餐饮娱乐知识图谱——美团大脑（相关信息请参见&lt;a href=&#34;https://tech.meituan.com/meituan_AI_NLP.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;《美团大脑：知识图谱的建模方法及其应用》&lt;/a&gt;）。它充分挖掘关联各个场景数据，用NLP技术让机器“阅读”用户公开评论，理解用户在菜品、价格、服务、环境等方面的喜好，构建人、店、商品、场景之间的知识关联，从而形成一个“知识大脑”[1]。通过将知识图谱信息加入到搜索各个流程中，我们对点评搜索的整体架构进行了升级重塑，图1为点评搜索基于知识图谱搭建的5层搜索架构。本篇文章是“美团大脑”系列文章第二篇（系列首篇文章请参见&lt;a href=&#34;https://tech.meituan.com/meituan_brain_NLP_01.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;《美团餐饮娱乐知识图谱——美团大脑揭秘》&lt;/a&gt;)，主要介绍点评搜索5层架构中核心排序层的演变过程，文章主要分为如下3个部分：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;核心排序从传统机器学习模型到大规模深度学习模型的演进。&lt;/li&gt;
&lt;li&gt;搜索场景深度学习排序模型的特征工程实践。&lt;/li&gt;
&lt;li&gt;适用于搜索场景的深度学习Listwise排序算法——LambdaDNN。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;https://p0.meituan.net/travelcube/32f3a2e20a8e8012aa2289d2281d045e187661.png&#34; alt=&#34;图1 基于知识图谱的点评搜索5层架构&#34; /&gt;&lt;/p&gt;

&lt;p&gt;图1 基于知识图谱的点评搜索5层架构&lt;/p&gt;

&lt;h2 id=&#34;2-排序模型探索与实践&#34;&gt;2. 排序模型探索与实践&lt;/h2&gt;

&lt;p&gt;搜索排序问题在机器学习领域有一个单独的分支，Learning to Rank（L2R）。主要分类如下:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;根据样本生成方法和Loss Function的不同，L2R可以分为Pointwise、Pairwise、Listwise。&lt;/li&gt;
&lt;li&gt;按照模型结构划分，可以分为线性排序模型、树模型、深度学习模型，他们之间的组合（GBDT+LR，Deep&amp;amp;Wide等）。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在排序模型方面，点评搜索也经历了业界比较普遍的迭代过程：从早期的线性模型LR，到引入自动二阶交叉特征的FM和FFM，到非线性树模型GBDT和GBDT+LR，到最近全面迁移至大规模深度学习排序模型。下面先简单介绍下传统机器学习模型（LR、FM、GBDT）的应用和优缺点，然后详细介绍深度模型的探索实践过程。&lt;/p&gt;

&lt;h4 id=&#34;传统机器学习模型&#34;&gt;传统机器学习模型&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://p1.meituan.net/travelcube/58920553566822f1fe059f95eba71d95131646.png&#34; alt=&#34;图2 几种传统机器学习模型结构&#34; /&gt;&lt;/p&gt;

&lt;p&gt;图2 几种传统机器学习模型结构&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;LR可以视作单层单节点的线性网络结构。模型优点是可解释性强。通常而言，良好的解释性是工业界应用实践比较注重的一个指标，它意味着更好的可控性，同时也能指导工程师去分析问题优化模型。但是LR需要依赖大量的人工特征挖掘投入，有限的特征组合自然无法提供较强的表达能力。&lt;/li&gt;
&lt;li&gt;FM可以看做是在LR的基础上增加了一部分二阶交叉项。引入自动的交叉特征有助于减少人工挖掘的投入，同时增加模型的非线性，捕捉更多信息。FM能够自动学习两两特征间的关系，但更高量级的特征交叉仍然无法满足。&lt;/li&gt;
&lt;li&gt;GBDT是一个Boosting的模型，通过组合多个弱模型逐步拟合残差得到一个强模型。树模型具有天然的优势，能够很好的挖掘组合高阶统计特征，兼具较优的可解释性。GBDT的主要缺陷是依赖连续型的统计特征，对于高维度稀疏特征、时间序列特征不能很好的处理。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;深度神经网络模型&#34;&gt;深度神经网络模型&lt;/h4&gt;

&lt;p&gt;随着业务的发展，在传统模型上取得指标收益变得愈发困难。同时业务的复杂性要求我们引入海量用户历史数据，超大规模知识图谱特征等多维度信息源，以实现精准个性化的排序。因此我们从2018年下半年开始，全力推进L2核心排序层的主模型迁移至深度学习排序模型。深度模型优势体现在如下几个方面：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;强大的模型拟合能力&lt;/strong&gt;：深度学习网络包含多个隐藏层和隐藏结点，配合上非线性的激活函数，理论上可以拟合任何函数，因此十分适用于点评搜索这种复杂的场景。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;强大的特征表征和泛化能力&lt;/strong&gt;：深度学习模型可以处理很多传统模型无法处理的特征。例如深度网络可以直接中从海量训练样本中学习到高维稀疏ID的隐含信息，并通过Embedding的方式去表征；另外对于文本、序列特征以及图像特征，深度网络均有对应的结构或者单元去处理。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;自动组合和发现特征的能力&lt;/strong&gt;：华为提出的DeepFM，以及Google提出的DeepCrossNetwork可以自动进行特征组合，代替大量人工组合特征的工作。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;下图是我们基于Google提出的Wide&amp;amp;Deep模型搭建的网络结构[2]。其中Wide部分输入的是LR、GBDT阶段常用的一些细粒度统计特征。通过较长周期统计的高频行为特征，能够提供很好的记忆能力。Deep部分通过深层的神经网络学习Low-Order、高纬度稀疏的Categorical型特征，拟合样本中的长尾部分，发现新的特征组合，提高模型的泛化能力。同时对于文本、头图等传统机器学习模型难以刻画的特征，我们可以通过End-to-End的方式，利用相应的子网络模型进行预处理表示，然后进行融合学习。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://p0.meituan.net/travelcube/5b5f704e77a7bb903c5b5f1c8050127d53152.png&#34; alt=&#34;图3 Deep&amp;amp;Wide模型结构图&#34; /&gt;&lt;/p&gt;

&lt;p&gt;图3 Deep&amp;amp;Wide模型结构图&lt;/p&gt;

&lt;h2 id=&#34;3-搜索深度排序模型的特征工程实践&#34;&gt;3. 搜索深度排序模型的特征工程实践&lt;/h2&gt;

&lt;p&gt;深度学习的横空出世，将算法工程师从很多人工挖掘和组合特征的事情中解放出来。甚至有一种论调，专做特征工程的算法工程师可能面临着失业的风险。但是深度学习的自动特征学习目前主要集中体现在CV领域，CV领域的特征数据是图片的像素点——稠密的低阶特征，深度学习通过卷积层这个强力工具，可以自动对低阶特征进行组合和变换，相比之前人工定义的图像特征从效果上来说确实更加显著。在NLP领域因为Transformer的出现，在自动特征挖掘上也有了长足的进步，BERT利用Transformer在多个NLP Task中取得了State-of-The-Art的效果。&lt;/p&gt;

&lt;p&gt;但是对于CTR预估和排序学习的领域，目前深度学习尚未在自动特征挖掘上对人工特征工程形成碾压之势，因此人工特征工程依然很重要。当然，深度学习在特征工程上与传统模型的特征工程也存在着一些区别，我们的工作主要集中在如下几个方面。&lt;/p&gt;

&lt;h3 id=&#34;3-1-特征预处理&#34;&gt;3.1 特征预处理&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;特征归一化&lt;/strong&gt;：深度网络的学习几乎都是基于反向传播，而此类梯度优化的方法对于特征的尺度非常敏感。因此，需要对特征进行归一化或者标准化以促使模型更好的收敛。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;特征离散化&lt;/strong&gt;：工业界一般很少直接使用连续值作为特征，而是将特征离散化后再输入到模型中。一方面因为离散化特征对于异常值具有更好的鲁棒性，其次可以为特征引入非线性的能力。并且，离散化可以更好的进行Embedding，我们主要使用如下两种离散化方法：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;等频分桶：按样本频率进行等频切分，缺失值可以选择给一个默认桶值或者单独设置分桶。&lt;/li&gt;
&lt;li&gt;树模型分桶：等频离散化的方式在特征分布特别不均匀的时候效果往往不好。此时可以利用单特征结合Label训练树模型，以树的分叉点做为切分值，相应的叶子节点作为桶号。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;特征组合&lt;/strong&gt;：基于业务场景对基础特征进行组合，形成更丰富的行为表征，为模型提供先验信息，可加速模型的收敛速度。典型示例如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;用户性别与类目之间的交叉特征，能够刻画出不同性别的用户在类目上的偏好差异，比如男性用户可能会较少关注“丽人”相关的商户。&lt;/li&gt;
&lt;li&gt;时间与类目之间的交叉特征，能够刻画出不同类目商户在时间上的差异，例如，酒吧在夜间会更容易被点击。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;3-2-万物皆可embedding&#34;&gt;3.2 万物皆可Embedding&lt;/h3&gt;

&lt;p&gt;深度学习最大的魅力在于其强大的特征表征能力，在点评搜索场景下，我们有海量的用户行为数据，有丰富的商户UGC信息以及美团大脑提供的多维度细粒度标签数据。我们利用深度学习将这些信息Embedding到多个向量空间中，通过Embedding去表征用户的个性化偏好和商户的精准画像。同时向量化的Embedding也便于深度模型进一步的泛化、组合以及进行相似度的计算。&lt;/p&gt;

&lt;h4 id=&#34;3-2-1-用户行为序列的embedding&#34;&gt;3.2.1 用户行为序列的Embedding&lt;/h4&gt;

&lt;p&gt;用户行为序列（搜索词序列、点击商户序列、筛选行为序列）包含了用户丰富的偏好信息。例如用户筛选了“距离优先”时，我们能够知道当前用户很有可能是一个即时消费的场景，并且对距离较为敏感。行为序列特征一般有如下图所示的三种接入方式:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Pooling&lt;/strong&gt;：序列Embedding后接入Sum/Average Pooling层。此方式接入成本低，但忽略了行为的时序关系。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RNN&lt;/strong&gt;：LSTM/GRU接入，利用循环网络进行聚合。此方式能够考虑行为序列的时序关系；代价是增大了模型复杂度，影响线上预测性能。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Attention&lt;/strong&gt;：序列Embedding后引入Attention机制，表现为加权的Sum Pooling；相比LSTM/GRU计算开销更低[4]。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://p1.meituan.net/travelcube/1ca2aec6e28804c77df9327ec1996f32320946.png&#34; alt=&#34;图4 行为序列特征接入的几种方法&#34; /&gt;&lt;/p&gt;

&lt;p&gt;图4 行为序列特征接入的几种方法&lt;/p&gt;

&lt;p&gt;同时，为了突显用户长期偏好和短期偏好对于排序的不同影响，我们按照时间维度对行为序列进行了划分：Session、半小时、一天、一周等粒度，也在线上取得了收益。&lt;/p&gt;

&lt;h4 id=&#34;3-2-2-用户id的embedding&#34;&gt;3.2.2 用户ID的Embedding&lt;/h4&gt;

&lt;p&gt;一种更常见的刻画用户偏好的方式，是直接将用户ID经过Embedding后作为特征接入到模型中，但是最后上线的效果却不尽如人意。通过分析用户的行为数据，我们发现相当一部分用户ID的行为数据较为稀疏，导致用户ID的Embedding没有充分收敛，未能充分刻画用户的偏好信息。&lt;/p&gt;

&lt;p&gt;Airbnb发表在KDD 2018上的文章为这种问题提供了一种解决思路[9]——利用用户基础画像和行为数据对用户ID进行聚类。Airbnb的主要场景是为旅游用户提供民宿短租服务，一般用户一年旅游的次数在1-2次之间，因此Airbnb的用户行为数据相比点评搜索会更为稀疏一些。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://p0.meituan.net/travelcube/a4ff86235924344c9ca43eab14b20694156329.png&#34; alt=&#34;图5 按照用户画像和行为信息聚类&#34; /&gt;&lt;/p&gt;

&lt;p&gt;图5 按照用户画像和行为信息聚类&lt;/p&gt;

&lt;p&gt;如上图所示，将用户画像特征和行为特征进行离散分桶，拼接特征名和所属桶号，得到的聚类ID为：US_lt1_pn3_pg3_r3_5s4_c2_b1_bd2_bt2_nu3。&lt;/p&gt;

&lt;p&gt;我们也采取了类似Airbnb的方案，稀疏性的问题得到了很好的解决，并且这样做还获得了一些额外的收益。大众点评作为一个本地化的生活信息服务平台，大部分用户的行为都集中自己的常驻地，导致用户到达一个新地方时，排序个性化明显不足。通过这种聚类的方式，将异地有相同行为的用户聚集在一起，也能解决一部分跨站的个性化问题。&lt;/p&gt;

&lt;h4 id=&#34;3-2-3-商户信息embedding&#34;&gt;3.2.3 商户信息Embedding&lt;/h4&gt;

&lt;p&gt;商户Embedding除了可以直接将商户ID加入模型中之外，美团大脑也利用深度学习技术对UGC进行大量挖掘，对商家的口味、特色等细粒度情感进行充分刻画，例如下图所示的“好停车”、“菜品精致”、“愿意再次光顾”等标签。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://p0.meituan.net/travelcube/9cd80ab828bbbbe0d2959521f9d40673603094.png&#34; alt=&#34;图6 美团大脑提供的商家细粒度情感标签&#34; /&gt;&lt;/p&gt;

&lt;p&gt;图6 美团大脑提供的商家细粒度情感标签&lt;/p&gt;

&lt;p&gt;这些信息与单纯的商户星级、点评数相比，刻画的角度更多，粒度也更细。我们将这些标签也进行Embedding并输入到模型中：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;直连&lt;/strong&gt;：将标签特征做Pooling后直接输入模型。这种接入方式适合端到端的学习方式；但受输入层大小限制，只能取Top的标签，容易损失抽象实体信息。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分组直连&lt;/strong&gt;：类似于直连接入的方式，但是先对标签进行分类，如菜品/风格/口味等类别；每个分类取Top N的实体后进行Pooling生成不同维度的语义向量。与不分组的直连相比，能够保留更多抽象信息。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;子模型接入&lt;/strong&gt;：可以利用DSSM模型，以标签作为商户输入学习商户的Embedding表达。此种方式能够最大化保留标签的抽象信息，但是线上实现和计算成本较高。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;3-2-4-加速embedding特征的收敛&#34;&gt;3.2.4 加速Embedding特征的收敛&lt;/h4&gt;

&lt;p&gt;在我们的深度学习排序模型中，除了Embedding特征，也存在大量Query、Shop和用户维度的强记忆特征，能够很快收敛。而Embedding特征是更为稀疏的弱特征，收敛速度较慢，为了加速Embedding特征的收敛，我们尝试了如下几种方案：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;低频过滤&lt;/strong&gt;：针对出现频率较低的特征进行过滤，可以很大程度上减少参数量，避免过拟合。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;预训练&lt;/strong&gt;：利用多类模型对稀疏Embedding特征进行预训练，然后进入模型进行微调：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;通过无监督模型如Word2vec、Fasttext对用户-商户点击关系建模，生成共现关系下的商户Embedding。&lt;/li&gt;
&lt;li&gt;利用DSSM等监督模型对Query-商户点击行为建模得到Query和商户的Embedding。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Multi-Task&lt;/strong&gt;：针对稀疏的Embedding特征，单独设置一个子损失函数，如下图所示。此时Embedding特征的更新依赖两个损失函数的梯度，而子损失函数脱离了对强特征的依赖，可以加快Embedding特征的收敛。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://p0.meituan.net/travelcube/47ad89d628dab207e4ac3bf9df3401a899773.png&#34; alt=&#34;图7 Multi-Task加速Embedding特征收敛&#34; /&gt;&lt;/p&gt;

&lt;p&gt;图7 Multi-Task加速Embedding特征收敛&lt;/p&gt;

&lt;h3 id=&#34;3-3-图片特征&#34;&gt;3.3 图片特征&lt;/h3&gt;

&lt;p&gt;图片在搜索结果页中占据了很大的展示面积，图片质量的好坏会直接影响用户的体验和点击，而点评商户首图来自于商户和用户上传的图片，质量参差不齐。因此，图片特征也是排序模型中较为重要的一类。目前点评搜索主要用了以下几类图片特征：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;基础特征&lt;/strong&gt;：提取图片的亮度、色度饱和度等基础信息，进行特征离散化后得到图片基础特征。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;泛化特征&lt;/strong&gt;：使用ResNet50进行图片特征提取[3]，通过聚类得到图片的泛化特征。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;质量特征&lt;/strong&gt;：使用自研的图片质量模型，提取中间层输出，作为图片质量的Embedding特征。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;标签特征&lt;/strong&gt;：提取图片是否是食物、环境、价目表、Logo等作为图片分类和标签特征。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://p1.meituan.net/travelcube/648914cb4522bfae32d0838eb1568d9396777.png&#34; alt=&#34;图8 图片特征接入&#34; /&gt;&lt;/p&gt;

&lt;p&gt;图8 图片特征接入&lt;/p&gt;

&lt;h2 id=&#34;4-适用于搜索场景的深度学习listwise排序算法-lambdadnn&#34;&gt;4. 适用于搜索场景的深度学习Listwise排序算法：LambdaDNN&lt;/h2&gt;

&lt;h3 id=&#34;4-1-搜索业务指标与模型优化目标的gap&#34;&gt;4.1 搜索业务指标与模型优化目标的Gap&lt;/h3&gt;

&lt;p&gt;通常模型的预测目标与业务指标总会存在一些Gap。如果模型的预测目标越贴近业务目标，越能保证模型优化的同时业务指标也能够有相应的提升；反之则会出现模型离线指标提升，但线上关键业务指标提升不明显，甚至出现负向的问题。工业届大部分深度学习排序采用Pointwise的Log Loss作为损失函数，与搜索业务指标有较大的Gap。体现在如下两个方面：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;搜索业务常用的指标有QV_CTR或者SSR(Session Success Rate)，更关心的是用户搜索的成功率（有没有发生点击行为）；而Pointwise的Log Loss更多是关注单个Item的点击率。&lt;/li&gt;
&lt;li&gt;搜索业务更关心排在页面头部结果的好坏，而Pointwise的方法则对于所有位置的样本一视同仁。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;https://p1.meituan.net/travelcube/234ae43befdfbf093e5d7cf8a736fcb1519826.png&#34; alt=&#34;图9 Pointwise和Listwise优化目标的区别&#34; /&gt;&lt;/p&gt;

&lt;p&gt;图9 Pointwise和Listwise优化目标的区别&lt;/p&gt;

&lt;p&gt;基于上述理由，我们对于深度学习模型的损失函数进行了优化。&lt;/p&gt;

&lt;h3 id=&#34;4-2-优化目标改进-从log-loss到ndcg&#34;&gt;4.2 优化目标改进：从Log Loss到NDCG&lt;/h3&gt;

&lt;p&gt;为了让排序模型的优化目标尽量贴近搜索业务指标，需要按照Query计算损失，且不同位置的样本具有不同的权重。搜索系统常用的指标NDCG(Normalized Discounted Cumulative Gain)相较于Log Loss显然更贴近搜索业务的要求，NDCG计算公式如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://p0.meituan.net/travelcube/c5f432c61fda6b290748d867a621ce2982758.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;p&gt;累加部分为DCG(Discounted Cumulative Gain)表示按照位置折损的收益，对于Query下的结果列表l，函数G表示对应Doc的相关度分值，通常取指数函数，即G(lj)=2lj-1（lj表示的是相关度水平，如{0，1，2}）；函数 η 即位置折损，一般采用 η(j)=1/log(j+1)，Doc与Query的相关度越高且位置越靠前则DCG值会越大。另外，通常我们仅关注排序列表页前k位的效果，Zk 表示 DCG@k 的可能最大值，以此进行归一化处理后得到的就是NDCG@k。&lt;/p&gt;

&lt;p&gt;问题在于NDCG是一个处处非平滑的函数，直接以它为目标函数进行优化是不可行的。LambdaRank提供了一种思路：绕过目标函数本身，直接构造一个特殊的梯度，按照梯度的方向修正模型参数，最终能达到拟合NDCG的方法[6]。因此，如果我们能将该梯度通过深度网络进行反向传播，则能训练一个优化NDCG的深度网络，该梯度我们称之为Lambda梯度，通过该梯度构造出的深度学习网络称之为LambdaDNN。&lt;/p&gt;

&lt;p&gt;要了解Lambda梯度需要引入LambdaRank。LambdaRank模型是通过Pairwise来构造的，通常将同Query下有点击样本和无点击样本构造成一个样本Pair。模型的基本假设如下式所示，令Pij为同一个Query下Doci相比Docj更相关的概率，其中si和sj分别为Doci和Docj的模型得分：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://p1.meituan.net/travelcube/72c7fd7af050286f7c6e9d7c01d169ed14109.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;p&gt;使用交叉熵为损失函数，令Sij表示样本Pair的真实标记，当Doci比Docj更相关时（即Doci有被用户点击，而Docj没有被点击），有Sij=1，否则为-1；则损失函数可以表示为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://p0.meituan.net/travelcube/8fdacb894b7bcecae87ae7467d557f6c18896.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在构造样本Pair时，我们可以始终令i为更相关的文档，此时始终有Sij≡1，代入上式并进行求导，则损失函数的梯度为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://p1.meituan.net/travelcube/e8e9c258ccac9e117dbf7125128837b617696.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;p&gt;到目前为止，损失函数的计算过程中并未考虑样本所在的位置信息。因此进一步对梯度进行改造，考虑Doci和Docj交换位置时的NDCG值变化，下式即为前述的Lambda梯度。可以证明，通过此种方式构造出来的梯度经过迭代更新，最终可以达到优化NDCG的目的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://p1.meituan.net/travelcube/4245218f0d1f3ceff72840a4ec9adff522385.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Lambda梯度的物理意义如下图所示。其中蓝色表示更相关（用户点击过）的文档，则Lambda梯度更倾向于位置靠上的Doc得到的提升更大（如红色箭头所示）。有了Lambda梯度的计算方法，训练中我们利用深度网络预测同Query下的Doc得分，根据用户实际点击Doc的情况计算Lambda梯度并反向传播回深度网络，则可以得到一个直接预测NDCG的深度网络。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://p0.meituan.net/travelcube/d6142123b31212f4854fd4e53da5831e14664.png&#34; alt=&#34;图10 Lambda梯度的物理意义&#34; /&gt;&lt;/p&gt;

&lt;p&gt;图10 Lambda梯度的物理意义&lt;/p&gt;

&lt;h3 id=&#34;4-3-lambdadnn的工程实施&#34;&gt;4.3 LambdaDNN的工程实施&lt;/h3&gt;

&lt;p&gt;我们利用TensorFlow分布式框架训练LambdaDNN模型。如前文所述，Lambda梯度需要对同Query下的样本进行计算，但是正常情况下所有的样本是随机Shuffle到各个Worker的。因此我们需要对样本进行预处理：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;通过QueryId进行Shuffle，将同一个Query的样本聚合在一起，同一个Query的样本打包进一个TFRecord。&lt;/li&gt;
&lt;li&gt;由于每次请求Query召回的Doc数不一样，对于可变Size的Query样本在拉取数据进行训练时需要注意，TF会自动补齐Mini-Batch内每个样本大小一致，导致输入数据中存在大量无意义的默认值样本。这里我们提供两点处理方式：

&lt;ul&gt;
&lt;li&gt;MR过程中对Key进行处理，使得多个Query的样本聚合在一起，然后在训练的时候进行动态切分。&lt;/li&gt;
&lt;li&gt;读取到补齐的样本，根据设定的补齐标记获取索引位，去除补齐数据。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;https://p0.meituan.net/travelcube/71677c27e2a62806f6d1fdf1d55020c6277900.png&#34; alt=&#34;图11 Lambda梯度的分布式实现&#34; /&gt;&lt;/p&gt;

&lt;p&gt;图11 Lambda梯度的分布式实现&lt;/p&gt;

&lt;p&gt;为了提升训练效率，我们与基础研发平台数据平台中心紧密协同，一起探索并验证了多项优化操作：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将ID类特征的映射等操作一并在预处理中完成，减少多轮Training过程中的重复计算。&lt;/li&gt;
&lt;li&gt;将样本转TfRecord，利用RecordDataSet方式读取数据并计算处理，Worker的计算性能大概提升了10倍。&lt;/li&gt;
&lt;li&gt;Concat多个Categorical特征，组合成Multi-Hot的Tensor进行一次Embedding_Lookup操作，减少Map操作的同时有助于参数做分片存储计算。&lt;/li&gt;
&lt;li&gt;稀疏Tensor在计算梯度以及正则化处理时保留索引值，仅对有数值的部分进行更新操作。&lt;/li&gt;
&lt;li&gt;多个PS服务器间进行分片存储大规模Tensor变量，减少Worker同步更新的通讯压力，减少更新阻塞，达到更平滑的梯度更新效果。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;整体下来，对于30亿左右的样本量、上亿级别的特征维度，一轮迭代大概在半小时内完成。适当的增加并行计算的资源，可以达到分钟级的训练任务。&lt;/p&gt;

&lt;h3 id=&#34;4-4-进一步改进优化目标&#34;&gt;4.4 进一步改进优化目标&lt;/h3&gt;

&lt;p&gt;NDCG的计算公式中，折损的权重是随着位置呈指数变化的。然而实际曝光点击率随位置变化的曲线与NDCG的理论折损值存在着较大的差异。&lt;/p&gt;

&lt;p&gt;对于移动端的场景来说，用户在下拉滑动列表进行浏览时，视觉的焦点会随着滑屏、翻页而发生变动。例如用户翻到第二页时，往往会重新聚焦，因此，会发现第二页头部的曝光点击率实际上是高于第一页尾部位置的。我们尝试了两种方案去微调NDCG中的指数位置折损：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;根据实际曝光点击率拟合折损曲线&lt;/strong&gt;：根据实际统计到的曝光点击率数据，拟合公式替代NDCG中的指数折损公式，绘制的曲线如图12所示。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;计算Position Bias作为位置折损&lt;/strong&gt;：Position Bias在业界有较多的讨论，其中[7][8]将用户点击商户的过程分为观察和点击两个步骤：a.用户需要首先看到该商户，而看到商户的概率取决于所在的位置；b.看到商户后点击商户的概率只与商户的相关性有关。步骤a计算的概率即为Position Bias，这块内容可以讨论的东西很多，这里不再详述。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;https://p1.meituan.net/travelcube/c795030e256addb3e5bd0b53ddf5eb0f70551.png&#34; alt=&#34;图12 真实位置折损与理论折损的差别&#34; /&gt;&lt;/p&gt;

&lt;p&gt;图12 真实位置折损与理论折损的差别&lt;/p&gt;

&lt;p&gt;经过上述对NDCG计算改造训练出的LambdaDNN模型，相较Base树模型和Pointwise DNN模型，在业务指标上有了非常显著的提升。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://p0.meituan.net/travelcube/3ce2e539d0f13c9725958f6ff8bef503108896.png&#34; alt=&#34;图13 LambdaDNN离线NDCG指标与线上PvCtr效果对比&#34; /&gt;&lt;/p&gt;

&lt;p&gt;图13 LambdaDNN离线NDCG指标与线上PvCtr效果对比&lt;/p&gt;

&lt;h3 id=&#34;4-5-lambda深度排序框架&#34;&gt;4.5 Lambda深度排序框架&lt;/h3&gt;

&lt;p&gt;Lambda梯度除了与DNN网络相结合外，事实上可以与绝大部分常见的网络结构相结合。为了进一步学习到更多交叉特征，我们在LambdaDNN的基础上分别尝试了LambdaDeepFM和LambdaDCN网络；其中DCN网络是一种加入Cross的并行网络结构，交叉的网络每一层的输出特征与第一层的原始输入特征进行显性的两两交叉，相当于每一层学习特征交叉的映射去拟合层之间的残差。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://p0.meituan.net/travelcube/fb151434e015d0e184228f55c7376c8937294.png&#34; alt=&#34;图14 DCN模型结构&#34; /&gt;&lt;/p&gt;

&lt;p&gt;图14 DCN模型结构&lt;/p&gt;

&lt;p&gt;离线的对比实验表明，Lambda梯度与DCN网络结合之后充分发挥了DCN网络的特点，简洁的多项式交叉设计有效地提升模型的训练效果。NDCG指标对比效果如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://p0.meituan.net/travelcube/14b1f47488954d1d0334492fc94cb40a45200.png&#34; alt=&#34;图15 Lambda Loss与DCN网络结果的效果&#34; /&gt;&lt;/p&gt;

&lt;p&gt;图15 Lambda Loss与DCN网络结果的效果&lt;/p&gt;

&lt;h2 id=&#34;5-深度学习排序诊断系统&#34;&gt;5. 深度学习排序诊断系统&lt;/h2&gt;

&lt;p&gt;深度学习排序模型虽然给业务指标带来了大幅度的提升，但由于深度学习模型的“黑盒属性”导致了巨大的解释性成本，也给搜索业务带来了一些问题：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;日常搜索Bad Case无法快速响应&lt;/strong&gt;：搜索业务日常需要应对大量来自于用户、业务和老板们的“灵魂拷问”，“为何这个排序是这样的”，“为什么这家商户质量跟我差不多，但是会排在我的前面”。刚切换到深度学习排序模型的时候，我们对于这样的问题显得手足无措，需要花费大量的时间去定位问题。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;无法从Bad Case中学习总结规律持续优化&lt;/strong&gt;：如果不明白为什么排序模型会得出一个很坏的排序结果，自然也无法定位模型到底出了什么问题，也就无法根据Bad Case总结规律，从而确定模型和特征将来的优化方向。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;模型和特征是否充分学习无从得知&lt;/strong&gt;：新挖掘一些特征之后，通常我们会根据离线评测指标是否有提升决定特征是否上线。但是，即使一个有提升的特征，我们也无法知道这个特征是否性能足够好。例如，模型拟合的距离特征，会不会在特定的距离段出现距离越远反而打分越高的情况。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这些问题都会潜在带来一些用户无法理解的排序结果。我们需要对深度排序模型清晰地诊断并解释。&lt;/p&gt;

&lt;p&gt;关于机器学习模型的可解释性研究，业界已经有了一些探索。Lime(Local Interpretable Model-Agnostic Explanations)是其中的一种，如下图所示：通过对单个样本的特征生成扰动产生近邻样本，观察模型的预测行为。根据这些扰动的数据点距离原始数据的距离分配权重，基于它们学习得到一个可解释的模型和预测结果[5]。举个例子，如果需要解释一个情感分类模型是如何预测“我讨厌这部电影”为负面情感的，我们通过丢掉部分词或者乱序构造一些样本预测情感，最终会发现，决定“我讨厌这部电影”为负面情感的是因为“讨厌”这个词。&lt;img src=&#34;https://p0.meituan.net/travelcube/92352b078811a5e2dfd1c69dc6376cf428921.png&#34; alt=&#34;图16 Lime解释器的工作原理&#34; /&gt;&lt;/p&gt;

&lt;p&gt;图16 Lime解释器的工作原理&lt;/p&gt;

&lt;p&gt;基于Lime解释器的思想，我们开发了一套深度模型解释器工具——雅典娜系统。目前雅典娜系统支持两种工作模式，Pairwise和Listwise模式：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Pairwise模式用来解释同一个列表中两个结果之间的相对排序。通过对样本的特征进行重新赋值或者替换等操作，观察样本打分和排序位次的变化趋势，诊断出当前样本排序是否符合预期。如下图所示，通过右侧的特征位次面板可以快速诊断出为什么“南京大牌档”的排序比“金时代顺风港湾”要更靠前。第一行的特征位次信息显示，若将“金时代顺风港湾”的1.3km的距离特征用“南京大牌档”的0.2km的距离特征进行替换，排序位次将上升10位；由此得出，“南京大牌档”排在前面的决定性因素是因为距离近。&lt;/li&gt;
&lt;li&gt;Listwise模式与Lime的工作模式基本类似，通过整个列表的样本生成扰动样本，训练线性分类器模型输出特征重要度，从而达到对模型进行解释的目的。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;https://p0.meituan.net/travelcube/317d3378665bb7b6af93499361e7181f142820.png&#34; alt=&#34;图17 深度学习排序诊断系统：雅典娜&#34; /&gt;&lt;/p&gt;

&lt;p&gt;图17 深度学习排序诊断系统：雅典娜&lt;/p&gt;

&lt;h2 id=&#34;6-总结与展望&#34;&gt;6. 总结与展望&lt;/h2&gt;

&lt;p&gt;2018年下半年，点评搜索完成了从树模型到大规模深度学习排序模型的全面升级。团队在深度学习特征工程、模型结构、优化目标以及工程实践上都进行了一些探索，在核心指标上取得了较为显著的收益。当然，未来依然有不少可以探索的点。&lt;/p&gt;

&lt;p&gt;在特征层面，大量知识图谱提供的标签信息尚未充分挖掘。从使用方式上看，简单以文本标签的形式接入，损失了知识图谱的结构信息，因此，Graph Embedding也是未来需要尝试的方向。同时团队也会利用BERT在Query和商户文本的深层语义表达上做一些工作。&lt;/p&gt;

&lt;p&gt;模型结构层面，目前线上依然以全连接的DNN网络结构为主，但DNN网络结构在低秩数据的学习上不如DeepFM和DCN。目前LambdaDeepFM和LambdaDCN在离线上已经取得了收益，未来会在网络结构上做进一步优化。&lt;/p&gt;

&lt;p&gt;在模型优化目标上，Lambda Loss计算损失的时候，只会考虑Query内部有点击和无点击的样本对，大量无点击的Query被丢弃，同时，同一个用户短时间内在不同Query下的行为也包含着一些信息可以利用。因此，目前团队正在探索综合考虑Log Loss和Lambda Loss的模型，通过Multi-Task和按照不同维度Shuffle样本让模型充分学习，目前我们已经在线下取得了一些收益。&lt;/p&gt;

&lt;p&gt;最后，近期Google开源的TF Ranking提出的Groupwise模型也对我们有一些启发。目前绝大部分的Listwise方法只是体现在模型训练阶段，在打分预测阶段依然是Pointwise的，即只会考虑当前商户相关的特征，而不会考虑列表上下文的结果，未来我们也会在这个方向上进行一些探索。&lt;/p&gt;

&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://tech.meituan.com/meituan_AI_NLP.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;美团大脑：知识图谱的建模方法及其应用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/1606.07792.pdf&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Wide &amp;amp; Deep Learning for Recommender Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1512.03385&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Deep Residual Learning for Image Recognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1706.03762&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Attention Is All You Need&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/1602.04938v1.pdf&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Local Interpretable Model-Agnostic Explanations: LIME&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://pdfs.semanticscholar.org/0df9/c70875783a73ce1e933079f328e8cf5e9ea2.pdf&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;From RankNet to LambdaRank to LambdaMART: An Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1809.05818&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;A Novel Algorithm for Unbiased Learning to Rank&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ijcai.org/proceedings/2018/0738.pdf&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Unbiased Learning-to-Rank with Biased Feedback&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://astro.temple.edu/~tua95067/kdd2018.pdf&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Real-time Personalization using Embeddings for Search Ranking at Airbnb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;作者简介&#34;&gt;作者简介&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;非易，2016年加入美团点评，高级算法工程师，目前主要负责点评搜索核心排序层的研发工作。&lt;/li&gt;
&lt;li&gt;祝升，2016年加入美团点评，高级算法工程师，目前负责点评搜索核心排序层的研发工作。&lt;/li&gt;
&lt;li&gt;汤彪，2013年加入美团点评，高级算法专家，点评平台搜索技术负责人，致力于深层次查询理解和大规模深度学习排序的技术落地。&lt;/li&gt;
&lt;li&gt;张弓，2012年加入美团点评，美团点评研究员。目前主要负责点评搜索业务演进，及集团搜索公共服务平台建设。&lt;/li&gt;
&lt;li&gt;仲远，博士，美团AI平台部NLP中心负责人，点评搜索智能中心负责人。在国际顶级学术会议发表论文30余篇，获得ICDE 2015最佳论文奖，并是ACL 2016 Tutorial “Understanding Short Texts”主讲人，出版学术专著3部，获得美国专利5项。此前，博士曾担任微软亚洲研究院主管研究员，以及美国Facebook公司Research Scientist。曾负责微软研究院知识图谱、对话机器人项目和Facebook产品级NLP Service。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;转载自：&lt;a href=&#34;https://tech.meituan.com/2019/01/17/dianping-search-deeplearning.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://tech.meituan.com/2019/01/17/dianping-search-deeplearning.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Elasticsearch面试题解读</title>
      <link>https://argsno.github.io/2019/elasticsearch%E9%9D%A2%E8%AF%95%E9%A2%98%E8%A7%A3%E8%AF%BB/</link>
      <pubDate>Sat, 26 Jan 2019 22:25:10 +0800</pubDate>
      
      <guid>https://argsno.github.io/2019/elasticsearch%E9%9D%A2%E8%AF%95%E9%A2%98%E8%A7%A3%E8%AF%BB/</guid>
      <description>

&lt;h2 id=&#34;题记&#34;&gt;题记&lt;/h2&gt;

&lt;p&gt;git上发现了网友总结的Elasticsearch BAT大厂面试题。只有题目，部分有答案，但不全。 正好抽出一些时间一起梳理一下。&lt;/p&gt;

&lt;p&gt;既然是面试题，每个人都会有自己的结合业务场景的答案，没有非常标准的答案。
欢迎大家留言拍砖指正。&lt;/p&gt;

&lt;h2 id=&#34;1-elasticsearch了解多少-说说你们公司es的集群架构-索引数据大小-分片有多少-以及一些调优手段&#34;&gt;1、elasticsearch了解多少，说说你们公司es的集群架构，索引数据大小，分片有多少，以及一些调优手段 。&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;面试官&lt;/strong&gt;：想了解应聘者之前公司接触的ES使用场景、规模，有没有做过比较大规模的索引设计、规划、调优。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;解答&lt;/strong&gt;：
如实结合自己的实践场景回答即可。
比如：ES集群架构13个节点，索引根据通道不同共20+索引，根据日期，每日递增20+，索引：10分片，每日递增1亿+数据，
每个通道每天索引大小控制：150GB之内。&lt;/p&gt;

&lt;p&gt;仅索引层面调优手段：&lt;/p&gt;

&lt;p&gt;1.1、设计阶段调优&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;根据业务增量需求，采取基于日期模板创建索引，通过roll over API滚动索引；&lt;/li&gt;
&lt;li&gt;使用别名进行索引管理；&lt;/li&gt;
&lt;li&gt;每天凌晨定时对索引做force_merge操作，以释放空间；&lt;/li&gt;
&lt;li&gt;采取冷热分离机制，热数据存储到SSD，提高检索效率；冷数据定期进行shrink操作，以缩减存储；&lt;/li&gt;
&lt;li&gt;采取curator进行索引的生命周期管理；&lt;/li&gt;
&lt;li&gt;仅针对需要分词的字段，合理的设置分词器；&lt;/li&gt;
&lt;li&gt;Mapping阶段充分结合各个字段的属性，是否需要检索、是否需要存储等。 …&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;1.2、写入调优&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;写入前副本数设置为0；&lt;/li&gt;
&lt;li&gt;写入前关闭refresh_interval设置为-1，禁用刷新机制；&lt;/li&gt;
&lt;li&gt;写入过程中：采取bulk批量写入；&lt;/li&gt;
&lt;li&gt;写入后恢复副本数和刷新间隔；&lt;/li&gt;
&lt;li&gt;尽量使用自动生成的id。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;1.3、查询调优&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;禁用wildcard；&lt;/li&gt;
&lt;li&gt;禁用批量terms（成百上千的场景）；&lt;/li&gt;
&lt;li&gt;充分利用倒排索引机制，能keyword类型尽量keyword；&lt;/li&gt;
&lt;li&gt;数据量大时候，可以先基于时间敲定索引再检索；&lt;/li&gt;
&lt;li&gt;设置合理的路由机制。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;1.4、其他调优&lt;/p&gt;

&lt;p&gt;部署调优，业务调优等。&lt;/p&gt;

&lt;p&gt;上面的提及一部分，面试者就基本对你之前的实践或者运维经验有所评估了。&lt;/p&gt;

&lt;h2 id=&#34;2-elasticsearch的倒排索引是什么&#34;&gt;2、elasticsearch的倒排索引是什么？&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;面试官&lt;/strong&gt;：想了解你对基础概念的认知。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;解答&lt;/strong&gt;：通俗解释一下就可以。&lt;/p&gt;

&lt;p&gt;传统的我们的检索是通过文章，逐个遍历找到对应关键词的位置。
而倒排索引，是通过分词策略，形成了词和文章的映射关系表，这种词典+映射表即为倒排索引。
有了倒排索引，就能实现o（1）时间复杂度的效率检索文章了，极大的提高了检索效率。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ws2.sinaimg.cn/large/006tNc79ly1fzkd4imut4j305d058mx7.jpg&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;p&gt;学术的解答方式：&lt;/p&gt;

&lt;p&gt;倒排索引，相反于一篇文章包含了哪些词，它从词出发，记载了这个词在哪些文档中出现过，由两部分组成——词典和倒排表。&lt;/p&gt;

&lt;p&gt;加分项：倒排索引的底层实现是基于：FST（Finite State Transducer）数据结构。
lucene从4+版本后开始大量使用的数据结构是FST。FST有两个优点：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;空间占用小。通过对词典中单词前缀和后缀的重复利用，压缩了存储空间；&lt;/li&gt;
&lt;li&gt;查询速度快。O(len(str))的查询时间复杂度。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;3-elasticsearch-索引数据多了怎么办-如何调优-部署&#34;&gt;3、elasticsearch 索引数据多了怎么办，如何调优，部署？&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;面试官&lt;/strong&gt;：想了解大数据量的运维能力。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;解答&lt;/strong&gt;：索引数据的规划，应在前期做好规划，正所谓“设计先行，编码在后”，这样才能有效的避免突如其来的数据激增导致集群处理能力不足引发的线上客户检索或者其他业务受到影响。
如何调优，正如问题1所说，这里细化一下：&lt;/p&gt;

&lt;h3 id=&#34;3-1-动态索引层面&#34;&gt;3.1 动态索引层面&lt;/h3&gt;

&lt;p&gt;基于&lt;code&gt;模板+时间+rollover api滚动&lt;/code&gt;创建索引，举例：设计阶段定义：blog索引的模板格式为：blog_index_时间戳的形式，每天递增数据。&lt;/p&gt;

&lt;p&gt;这样做的好处：不至于数据量激增导致单个索引数据量非常大，接近于上线2的32次幂-1，索引存储达到了TB+甚至更大。&lt;/p&gt;

&lt;p&gt;一旦单个索引很大，存储等各种风险也随之而来，所以要提前考虑+及早避免。&lt;/p&gt;

&lt;h3 id=&#34;3-2-存储层面&#34;&gt;3.2 存储层面&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;冷热数据分离存储&lt;/code&gt;，热数据（比如最近3天或者一周的数据），其余为冷数据。
对于冷数据不会再写入新数据，可以考虑定期force_merge加shrink压缩操作，节省存储空间和检索效率。&lt;/p&gt;

&lt;h3 id=&#34;3-3-部署层面&#34;&gt;3.3 部署层面&lt;/h3&gt;

&lt;p&gt;一旦之前没有规划，这里就属于应急策略。
结合ES自身的支持动态扩展的特点，动态新增机器的方式可以缓解集群压力，注意：如果之前主节点等规划合理，不需要重启集群也能完成动态新增的。&lt;/p&gt;

&lt;h2 id=&#34;4-elasticsearch是如何实现master选举的&#34;&gt;4、elasticsearch是如何实现master选举的？&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;面试官&lt;/strong&gt;：想了解ES集群的底层原理，不再只关注业务层面了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;解答&lt;/strong&gt;：
前置前提：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;只有候选主节点（master：true）的节点才能成为主节点。&lt;/li&gt;
&lt;li&gt;最小主节点数（min_master_nodes）的目的是防止脑裂。
这个我看了各种网上分析的版本和源码分析的书籍，云里雾里。
核对了一下代码，核心入口为findMaster，选择主节点成功返回对应Master，否则返回null。选举流程大致描述如下：&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;第一步：确认候选主节点数达标，elasticsearch.yml设置的值discovery.zen.minimum_master_nodes；
第二步：比较：先判定是否具备master资格，具备候选主节点资格的优先返回；若两节点都为候选主节点，则id小的值会主节点。注意这里的id为string类型。
题外话：获取节点id的方法。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-curl&#34;&gt;GET /_cat/nodes?v&amp;amp;h=ip,port,heapPercent,heapMax,id,name
ip        port heapPercent heapMax id   name
127.0.0.1 9300          39   1.9gb Hk9w Hk9wFwU
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;5-详细描述一下elasticsearch索引文档的过程&#34;&gt;5、详细描述一下Elasticsearch索引文档的过程？&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;面试官&lt;/strong&gt;：想了解ES的底层原理，不再只关注业务层面了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;解答&lt;/strong&gt;：
这里的索引文档应该理解为文档写入ES，创建索引的过程。
文档写入包含：单文档写入和批量bulk写入，这里只解释一下：单文档写入流程。&lt;/p&gt;

&lt;p&gt;记住官方文档中的这个图。&lt;/p&gt;

&lt;p&gt;第一步：客户写集群某节点写入数据，发送请求。（如果没有指定路由/协调节点，请求的节点扮演路由节点的角色。）&lt;/p&gt;

&lt;p&gt;第二步：节点1接受到请求后，使用文档_id来确定文档属于分片0。请求会被转到另外的节点，假定节点3。因此分片0的主分片分配到节点3上。&lt;/p&gt;

&lt;p&gt;第三步：节点3在主分片上执行写操作，如果成功，则将请求并行转发到节点1和节点2的副本分片上，等待结果返回。所有的副本分片都报告成功，节点3将向协调节点（节点1）报告成功，节点1向请求客户端报告写入成功。&lt;/p&gt;

&lt;p&gt;如果面试官再问：第二步中的文档获取分片的过程？
回答：借助路由算法获取，路由算法就是根据路由和文档id计算目标的分片id的过程。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-math&#34;&gt;shard = hash(_routing) % (num_of_primary_shards)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;6-详细描述一下elasticsearch搜索的过程&#34;&gt;6、详细描述一下Elasticsearch搜索的过程？&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;面试官&lt;/strong&gt;：想了解ES搜索的底层原理，不再只关注业务层面了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;解答&lt;/strong&gt;：
搜索拆解为“query then fetch” 两个阶段。
query阶段的目的：定位到位置，但不取。
步骤拆解如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;假设一个索引数据有5主+1副本 共10分片，一次请求会命中（主或者副本分片中）的一个。&lt;/li&gt;
&lt;li&gt;每个分片在本地进行查询，结果返回到本地有序的优先队列中。&lt;/li&gt;
&lt;li&gt;第2步骤的结果发送到协调节点，协调节点产生一个全局的排序列表。
fetch阶段的目的：取数据。
路由节点获取所有文档，返回给客户端。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;7-elasticsearch在部署时-对linux的设置有哪些优化方法&#34;&gt;7、Elasticsearch在部署时，对Linux的设置有哪些优化方法？&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;面试官&lt;/strong&gt;：想了解对ES集群的运维能力。
&lt;strong&gt;解答&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;关闭缓存swap;&lt;/li&gt;
&lt;li&gt;堆内存设置为：Min（节点内存/2, 32GB）;&lt;/li&gt;
&lt;li&gt;设置最大文件句柄数；&lt;/li&gt;
&lt;li&gt;线程池+队列大小根据业务需要做调整；&lt;/li&gt;
&lt;li&gt;磁盘存储raid方式——存储有条件使用RAID10，增加单节点性能以及避免单节点存储故障。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;8-lucence内部结构是什么&#34;&gt;8、lucence内部结构是什么？&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;面试官&lt;/strong&gt;：想了解你的知识面的广度和深度。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;解答&lt;/strong&gt;：
&lt;img src=&#34;https://ws3.sinaimg.cn/large/006tNc79ly1fzkd69t7wvj30ft0d9dic.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Lucene是有索引和搜索的两个过程，包含索引创建，索引，搜索三个要点。可以基于这个脉络展开一些。&lt;/p&gt;

&lt;h2 id=&#34;小结&#34;&gt;小结&lt;/h2&gt;

&lt;p&gt;看到题目后，感觉熟悉又陌生。真正要在面试的时候讲出来，需要下一番功夫深入理解。
为了求证回答的相对准确性，我翻看了源码、官方文档和部分有深度的博文。
Elasticsearch路还很长，别无他法，唯有死磕！&lt;/p&gt;

&lt;p&gt;题目来源：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/randian666/algorithm-study#搜索&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://github.com/randian666/algorithm-study#搜索&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cnblogs.com/luckcs/articles/7052932.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://www.cnblogs.com/luckcs/articles/7052932.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;核心参考：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cnblogs.com/LBSer/p/4119841.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;http://www.cnblogs.com/LBSer/p/4119841.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/njpjsoftdev/article/details/54015485&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://blog.csdn.net/njpjsoftdev/article/details/54015485&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://elasticsearch.cn/book/elasticsearch_definitive_guide_2.x/distrib-write.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://elasticsearch.cn/book/elasticsearch_definitive_guide_2.x/distrib-write.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cnblogs.com/forfuture1978/archive/2010/05/19/1738806.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;http://www.cnblogs.com/forfuture1978/archive/2010/05/19/1738806.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;《Elasticsearch源码解析和优化实践》&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Java GC</title>
      <link>https://argsno.github.io/2017/java-gc/</link>
      <pubDate>Thu, 07 Dec 2017 14:53:43 +0000</pubDate>
      
      <guid>https://argsno.github.io/2017/java-gc/</guid>
      <description>

&lt;h2 id=&#34;判断对象是否存活&#34;&gt;判断对象是否存活&lt;/h2&gt;

&lt;h3 id=&#34;引用计数法&#34;&gt;引用计数法&lt;/h3&gt;

&lt;p&gt;给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值加1；当引用失效时，计数器值减1；任何时刻计数器为0的对象就是还不可能再被使用的。实现简单，判定效率高，但很难解决对象之间相互循环引用的问题。&lt;/p&gt;

&lt;h3 id=&#34;可达性分析算法&#34;&gt;可达性分析算法&lt;/h3&gt;

&lt;p&gt;通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。&lt;/p&gt;

&lt;p&gt;在Java语言中，可作为GC Roots的对象包括下面几种：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;虚拟机栈（栈帧中的本地变量表）中引用的对象。&lt;/li&gt;
&lt;li&gt;方法区中类静态属性引用的对象。&lt;/li&gt;
&lt;li&gt;方法区中常量引用的对象。&lt;/li&gt;
&lt;li&gt;本地方法栈中JNI（即一般说的Native方法）引用的对象&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;java中的引用&#34;&gt;Java中的引用&lt;/h3&gt;

&lt;p&gt;Java将引用分为强引用（Strong Reference）、软引用（Soft Reference）、弱引用（Weak Reference）、虚引用（Phantom Reference）4种，这4种引用强度依次逐渐减弱。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;强引用：只要强引用还存在，垃圾收集器永远不会回收被引用的对象。&lt;/li&gt;
&lt;li&gt;软引用：在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收，Java中提供了SoftReference类来实现软引用。&lt;/li&gt;
&lt;li&gt;弱引用：被弱引用关联的对象只能生存到下一次垃圾收集发生之前。Java中提供了WeakReference类来实现弱引用。&lt;/li&gt;
&lt;li&gt;虚引用，也称为幽灵引用或者幻影引用：一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。Java中提供了PhantomReference类来实现虚引用。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;finalize方法&#34;&gt;finalize方法&lt;/h3&gt;

&lt;p&gt;如果对象在进行可达性分析之后发现没有与GC Roots相连接的引用链，那它将会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。当对象没有覆盖finalize()方法，或者finalize()方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”。&lt;/p&gt;

&lt;p&gt;如果这个对象被判定为有必要执行finalize()方法，那么这个对象将会放置在一个叫做F-Queue的队列之中，并在稍后由一个由虚拟机自动建立的、低优先级的Finalizer线程去执行它。&lt;/p&gt;

&lt;p&gt;任何一个对象的finalize()方法都只会被系统自动调用一次，如果对象面临下一次回收，它的finalize()方法不会被再次执行。finalize()能做的所有工作，使用try-finally或者其他方式都可以做得更好、更及时。&lt;/p&gt;

&lt;h2 id=&#34;垃圾收集算法&#34;&gt;垃圾收集算法&lt;/h2&gt;

&lt;h3 id=&#34;标记-清除算法&#34;&gt;标记-清除算法&lt;/h3&gt;

&lt;p&gt;首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。&lt;/p&gt;

&lt;p&gt;它的主要不足有两个：一个是效率问题，标记和清除两个过程的效率都不高；另一个是空间问题，标记清除之后会产生大量不连续的内存碎片。&lt;/p&gt;

&lt;h3 id=&#34;复制算法&#34;&gt;复制算法&lt;/h3&gt;

&lt;p&gt;将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活的对象复制到另一快上面，然后再把已使用过的内存一次清理掉。代价是将内存缩小为了原来的一半。&lt;/p&gt;

&lt;p&gt;现在的商业虚拟机都采用这种收集算法来回收新生代。但是并不需要按照1:1的比例划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。Hotspot虚拟机默认Eden和Survivor的大小比例是8:1。当Survivor空间不够用时，需要依赖其他内存（这里指老年代）进行分配担保。&lt;/p&gt;

&lt;h3 id=&#34;标记-整理算法&#34;&gt;标记-整理算法&lt;/h3&gt;

&lt;p&gt;根据老年代的特点，标记-整理算法的标记过程仍然与标记-清除算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一边移动，然后直接清理掉端边界以外的内存。&lt;/p&gt;

&lt;h3 id=&#34;分代收集算法&#34;&gt;分代收集算法&lt;/h3&gt;

&lt;p&gt;一般把Java堆分成新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。&lt;/p&gt;

&lt;h2 id=&#34;垃圾收集器&#34;&gt;垃圾收集器&lt;/h2&gt;

&lt;h3 id=&#34;serial收集器&#34;&gt;Serial收集器&lt;/h3&gt;

&lt;p&gt;单线程的收集器，并且在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。新生代收集器。复制算法。&lt;/p&gt;

&lt;h3 id=&#34;parnew收集器&#34;&gt;ParNew收集器&lt;/h3&gt;

&lt;p&gt;Serial收集器的多线程版本。新生代收集器。复制算法。&lt;/p&gt;

&lt;h3 id=&#34;parallel-scavenge收集器&#34;&gt;Parallel Scavenge收集器&lt;/h3&gt;

&lt;p&gt;新生代收集器。复制算法。并行的多线程收集器。Parallel Scavenge收集器的目的则是达到一个可控制的吞吐量。提供了两个参数用于精确控制吞吐量，分别是控制最大垃圾收集停顿时间的-XX:MaxGCPauseMillis参数以及直接设置吞吐量大小的-XX:GCTimeRatio参数。&lt;/p&gt;

&lt;h3 id=&#34;serial-old收集器&#34;&gt;Serial Old收集器&lt;/h3&gt;

&lt;p&gt;Serial收集器的老年代版本，单线程，使用标记-整理算法。&lt;/p&gt;

&lt;h3 id=&#34;parallel-old收集器&#34;&gt;Parallel Old收集器&lt;/h3&gt;

&lt;p&gt;Parallel Scavenge收集器的老年代版本，使用多线程和“标记-整理”算法。&lt;/p&gt;

&lt;h3 id=&#34;cms-concurrent-mark-sweep-收集器&#34;&gt;CMS（Concurrent Mark Sweep）收集器&lt;/h3&gt;

&lt;p&gt;以获取最短回收停顿时间为目标的收集器。CMS收集器是基于“标记-清除”算法实现的，包括以下4个步骤：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;初始标记（CMS initial mark）&lt;/li&gt;
&lt;li&gt;并发标记（CMS concurrent mark）&lt;/li&gt;
&lt;li&gt;重新标记（CMS remark）&lt;/li&gt;
&lt;li&gt;并发清除（CMS concurrent sweep）
其中，初始标记、重新标记这两个步骤仍然需要“Stop The World”。初始标记仅仅是标记一下GC Roots能直接关联到的对象，速度很快；并发标记阶段就是进行GC Roots Tracing的过程；而重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;g1收集器&#34;&gt;G1收集器&lt;/h3&gt;

&lt;p&gt;特点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;并行与并发：G1能充分利用多CPU、多核环境下的硬件优势。&lt;/li&gt;
&lt;li&gt;分代收集：G1可以不需要其他收集器配合就能独立管理整个GC堆。&lt;/li&gt;
&lt;li&gt;空间整合：G1从整体来看是基于“标记-整理”算法实现的收集器。&lt;/li&gt;
&lt;li&gt;可预测的停顿：G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;将整个Java堆划分为多个大小相等的独立区域（Region），跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region。&lt;/p&gt;

&lt;p&gt;步骤：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;初始标记（Initial Marking）&lt;/li&gt;
&lt;li&gt;并发标记（Concurrent Marking）&lt;/li&gt;
&lt;li&gt;最终标记（Final Marking）&lt;/li&gt;
&lt;li&gt;筛选回收（Live Data Counting and Evacuation）&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Java ClassLoader</title>
      <link>https://argsno.github.io/2017/java-classloader/</link>
      <pubDate>Wed, 06 Dec 2017 11:29:51 +0000</pubDate>
      
      <guid>https://argsno.github.io/2017/java-classloader/</guid>
      <description>

&lt;h2 id=&#34;类加载的时机&#34;&gt;类加载的时机&lt;/h2&gt;

&lt;p&gt;类的整个生命周期包括：加载（Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化（Initialization）、使用（Using）和卸载（Unloading）7个阶段。其中验证、准备、解析3个部分统称为连接（Linking）。&lt;/p&gt;

&lt;p&gt;虚拟机规范中严格规定了有且只有5种情况必须立即对类进行“初始化”：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;遇到new、getstatic、putstatic和invokestatic这4条字节码指令时，如果类没有进行过初始化，则需要触发其初始化。常见的Java代码场景：使用new关键字实例化对象的时候、读取或设置一个类的静态字段（被final修饰、已在编译器把结果放入常量池的静态字段除外）的时候，以及调用一个类的静态方法的时候。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;当初始化一个类的时候，如果发现其父类还没有初始化，则需要先触发其父类的初始化。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;当虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始化这个主类。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;当使用JDK 1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这5种场景中的行为称为对一个类进行主动调用。除此之外，所有引用类的方式都不会触发初始化，称为被动引用。被动引用包括：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;通过子类引用父类的静态字段，不会导致子类初始化。&lt;/li&gt;
&lt;li&gt;通过数组定义来引用类，不会触发类的初始化。&lt;/li&gt;
&lt;li&gt;常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;接口与类真正有所区别的初始化场景：在一个接口初始化时，并不要求其父接口全部都完成了初始化，只有在真正使用到父接口的时候（如引用接口中定义的常量）才会初始化。&lt;/p&gt;

&lt;h2 id=&#34;类加载的过程&#34;&gt;类加载的过程&lt;/h2&gt;

&lt;h3 id=&#34;加载&#34;&gt;加载&lt;/h3&gt;

&lt;p&gt;在加载阶段，虚拟机需要完成一下3件事情：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;通过一个类的全限定名来获取此类的二进制字节流。&lt;/li&gt;
&lt;li&gt;将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。&lt;/li&gt;
&lt;li&gt;在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;验证&#34;&gt;验证&lt;/h3&gt;

&lt;p&gt;验证是连接阶段的第一步。这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害自身的安全。
验证阶段大致会完成下面4个阶段的检验动作：文件格式验证、元数据验证、字节码验证、符号引用验证。文件格式验证是基于二进制字节流进行的，后面的3个验证阶段全部是基于方法区的存储结构进行的。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;文件格式验证：验证字节流是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理。&lt;/li&gt;
&lt;li&gt;元数据验证：对字节码描述的信息进行语义分析，已保证其描述的信息符合Java语言规范的要求。&lt;/li&gt;
&lt;li&gt;字节码验证：通过数据流和控制流分析，确保程序语义是合法的、符合逻辑的。&lt;/li&gt;
&lt;li&gt;符号引用验证：可以看做是对类自身以外（常量池中的各种符号引用）的信息进行匹配性校验。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;准备&#34;&gt;准备&lt;/h3&gt;

&lt;p&gt;准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。&lt;/p&gt;

&lt;h3 id=&#34;解析&#34;&gt;解析&lt;/h3&gt;

&lt;p&gt;解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。&lt;/p&gt;

&lt;h3 id=&#34;初始化&#34;&gt;初始化&lt;/h3&gt;

&lt;p&gt;初始化阶段是执行类构造器&lt;code&gt;&amp;lt;clinit&amp;gt;()&lt;/code&gt;方法的过程。&lt;/p&gt;

&lt;h2 id=&#34;类加载器&#34;&gt;类加载器&lt;/h2&gt;

&lt;h3 id=&#34;类与类加载器&#34;&gt;类与类加载器&lt;/h3&gt;

&lt;p&gt;类加载器只用于实现类的加载动作。对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在Java虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。&lt;/p&gt;

&lt;h3 id=&#34;双亲委派模型&#34;&gt;双亲委派模型&lt;/h3&gt;

&lt;p&gt;从Java虚拟机的角度来讲，只存在两种不同的类加载器：一种是启动类加载器（Bootstrap ClassLoader），是虚拟机自身的一部分；另一种就是所有其他的类加载器，这些类加载器都由Java语言实现，独立于虚拟机外部，并且全都继承自抽象类java.lang.ClassLoader。&lt;/p&gt;

&lt;p&gt;从Java开发人员的角度来看，类加载器还可以划分得更细致一些，绝大部分Java程序都会使用到以下3中系统提供的类加载器。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;启动类加载器：这个类加载器负责存放在&lt;JAVA_HOME&gt;/lib目录中的，或者被-Xbootclasspath参数所指定的路径中的，并且是虚拟机识别的类库加载到虚拟机内存中。启动类加载器无法被Java程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给引导类加载器，那直接使用null代替即可。&lt;/li&gt;
&lt;li&gt;扩展类加载器（Extension ClassLoader）：这个类加载器有sun.misc.Launcher$ExtClassLoader实现，它负责加载&lt;JAVA_HOME&gt;/lib/ext目录中的，或者被java.ext.dirs系统变量所指定的路径中的所有类库。开发者可以直接使用扩展类加载器。&lt;/li&gt;
&lt;li&gt;应用程序类加载器（Application ClassLoader）：这个类加载器由sun.misc.Launcher$AppClassLoader实现。它负责加载用户类路径（ClassPath）上所指定的类库。开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类机载器，一般情况下这个就是程序中默认的类加载器。&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Java 运行时数据区域</title>
      <link>https://argsno.github.io/2017/java-runtime-data/</link>
      <pubDate>Tue, 05 Dec 2017 10:33:17 +0000</pubDate>
      
      <guid>https://argsno.github.io/2017/java-runtime-data/</guid>
      <description>

&lt;h2 id=&#34;程序计数器&#34;&gt;程序计数器&lt;/h2&gt;

&lt;p&gt;当前线程所执行的字节码的行号指示器，用于记录下一条要执行的指令。每个线程都需要有一个独立的程序计数器，线程私有。
如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Native方法，这个计数器值则为空（Undefined）。&lt;/p&gt;

&lt;p&gt;此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。&lt;/p&gt;

&lt;h2 id=&#34;java虚拟机栈&#34;&gt;Java虚拟机栈&lt;/h2&gt;

&lt;p&gt;线程私有，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。局部变量表中存放了编译器可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型）和returnAddress类型（指向了一条字节码指令的地址）。其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。局部变量表所需的内存空间在编译期间完成分配，在方法运行期间不会改变局部变量表的大小。&lt;/p&gt;

&lt;p&gt;两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机栈可以动态扩展，如果扩展时无法申请到足够的内存，就会抛出OutOfMemoryError异常。&lt;/p&gt;

&lt;h2 id=&#34;本地方法栈&#34;&gt;本地方法栈&lt;/h2&gt;

&lt;p&gt;与虚拟机栈相似，只不过是为虚拟机所用到的Native方法服务。&lt;/p&gt;

&lt;h2 id=&#34;java堆&#34;&gt;Java堆&lt;/h2&gt;

&lt;p&gt;Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建，用于存放对象实例。可以通过-Xmx和-Xms控制大小。&lt;/p&gt;

&lt;p&gt;如果在堆中没有内存完成实例分配，并且堆也无法在扩展时，将会抛出OutOfMemoryError异常。&lt;/p&gt;

&lt;h2 id=&#34;方法区&#34;&gt;方法区&lt;/h2&gt;

&lt;p&gt;各个线程共享的内存区域。用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。这区域的内存回收目标主要针对常量池的回收和对类型的卸载。&lt;/p&gt;

&lt;p&gt;当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。&lt;/p&gt;

&lt;h2 id=&#34;运行时常量池&#34;&gt;运行时常量池&lt;/h2&gt;

&lt;p&gt;运行时常量池是方法区的一部分。用于存放Class文件中的常量池以及在运行期间可能将新的常量放入池中。&lt;/p&gt;

&lt;p&gt;当常量池无法再申请内存时会抛出OutOfMemoryError异常。&lt;/p&gt;

&lt;h2 id=&#34;直接内存&#34;&gt;直接内存&lt;/h2&gt;

&lt;p&gt;不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域。在NIO中通过避免在Java堆和Native堆中来回复制数据显著提高性能。&lt;/p&gt;

&lt;p&gt;经常被忽略导致可能动态扩展时出现OutOfMemoryError异常。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://argsno.github.io/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://argsno.github.io/about/</guid>
      <description>&lt;p&gt;Hugo is the &lt;strong&gt;world’s fastest framework for building websites&lt;/strong&gt;. It is written in Go.&lt;/p&gt;

&lt;p&gt;It makes use of a variety of open source projects including:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/russross/blackfriday&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://github.com/russross/blackfriday&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/alecthomas/chroma&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://github.com/alecthomas/chroma&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/muesli/smartcrop&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://github.com/muesli/smartcrop&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spf13/cobra&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://github.com/spf13/cobra&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spf13/viper&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://github.com/spf13/viper&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Learn more and contribute on &lt;a href=&#34;https://github.com/gohugoio&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on ArgsNo&#39;s Notes</title>
    <link>https://argsno.github.com/posts/</link>
    <description>Recent content in Posts on ArgsNo&#39;s Notes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 04 Feb 2019 15:15:08 +0800</lastBuildDate>
    
	<atom:link href="https://argsno.github.com/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>写日志的那些事儿</title>
      <link>https://argsno.github.com/2019/%E5%86%99%E6%97%A5%E5%BF%97%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/</link>
      <pubDate>Mon, 04 Feb 2019 15:15:08 +0800</pubDate>
      
      <guid>https://argsno.github.com/2019/%E5%86%99%E6%97%A5%E5%BF%97%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/</guid>
      <description>写日志简介 一般提到写日志，主要有下面几种不同的场景：
 诊断日志：应用打印异常信息，排查问题用，一般是给人看的，输出格式会比较随意，里面可能会有异常堆栈，或者排查问题用的一些文本信息； 数据日志：一般是用来做监控和数据分析的，可以人肉临时分析，也可以给机器分析，要求格式比较固定； 交易日志：一般在日志式文件系统、NoSQL、DB 中使用，一般有 journaling，WAL（write-ahead logging），binlog。这种日志通常都不是给人看的。  EagleEye 写的日志，是数据日志，记录的是中间件的网络调用埋点，或者是应用的业务埋点，它们都通过调用 eagleeye-core 的 EagleEye API 输出。 EagleEye 在写日志方面，有下面几个目标：
 写日志性能要足够好，应避免影响应用主流程； 写日志对系统影响尽量小，在系统压力很大的时候，甚至可以选择放弃输出日志。  在最老的实现里，EagleEye 使用了常见的 log4j 去写日志，在 1.1.3 版的大幅重构之后，就自己直接实现了写日志。 当时想法就是要简化写日志的逻辑，因为 EagleEye 并不是通用的写日志组件，而是写自己的埋点日志。不使用通用的日志框架，主要考虑有几点：
 自己写，可控性强，可以做专门定制化，有利于提升性能 避免日志组件的依赖冲突问题，不用再担心 Classloader 隔离、类加载等 可以把很多 EagleEye 不需要的通用逻辑砍掉，例如配置化、日志级别（LogLevel）、日志格式（Layout）、层次结构（Category）、多种输出实现（Appender）  从写日志这个功能上面讲，可以细分成三步：
 写日志到 logger：指调用 log(&amp;hellip;) 方法，把字符串和相关参数传到日志框架。对于框架来说，这是一个追加日志的事件（LogEvent）。 把日志编码成字符串或字节：指把日志事件格式化，编码成字符串或字节数组的过程，例如每行日志按照指定格式追加时间戳、日志级别、代码位置等信息，就是在这一步完成。 日志输出到目的地：通用日志框架可以指定多个输出目的地（Appender），目的地不仅可以是写本地文件，甚至可以是走网络、存数据库、发消息等。  下面就这三步，结合 EagleEye 关注的目标，说说在这些方面遇到了什么问题，以及如何实现的。
写日志到 logger 同步写的问题 多线程环境并发写日志，首先需要保证线程安全，就是说，多个线程一起写日志时，内容不能出现交织。 要做到这一点，最最简单的办法，就是每条线程单独写一个文件，这个方案在淘宝是不现实的，因为应用的线程非常多（仅 HSF 线程池就已经有 600 个线程），如果采用这个方案，会产生很多日志文件。 再简单一点的办法是把写日志作为临界区，进入临界区时用锁来保证每一时刻只有一个线程在写日志，例如 BufferedOutputStream 就是一个写时同步的实现。 应用用 log4j、logback 打日志，如果没特殊配置过，一般就是同步写的。
EagleEye 的 1.</description>
    </item>
    
    <item>
      <title>大众点评搜索基于知识图谱的深度学习排序实践</title>
      <link>https://argsno.github.com/2019/dianping-search-deeplearning/</link>
      <pubDate>Sat, 26 Jan 2019 23:03:32 +0800</pubDate>
      
      <guid>https://argsno.github.com/2019/dianping-search-deeplearning/</guid>
      <description>1. 引言 挑战与思路 搜索是大众点评App上用户进行信息查找的最大入口，是连接用户和信息的重要纽带。而用户搜索的方式和场景非常多样，并且由于对接业务种类多，流量差异大，为大众点评搜索（下文简称点评搜索）带来了巨大的挑战，具体体现在如下几个方面：
 意图多样：用户查找的信息类型和方式多样。信息类型包括POI、榜单、UGC、攻略、达人等。以找店为例，查找方式包括按距离、按热度、按菜品和按地理位置等多种方式。例如用户按照品牌进行搜索时，大概率是需要寻找距离最近或者常去的某家分店；但用户搜索菜品时，会对菜品推荐人数更加敏感，而距离因素会弱化。 业务多样：不同业务之间，用户的使用频率、选择难度以及业务诉求均不一样。例如家装场景用户使用频次很低，行为非常稀疏，距离因素弱，并且选择周期可能会很长；而美食多为即时消费场景，用户行为数据多，距离敏感。 用户类型多样：不同的用户对价格、距离、口味以及偏好的类目之间差异很大；搜索需要能深度挖掘到用户的各种偏好，实现定制化的“千人千面”的搜索。 LBS的搜索：相比电商和通用搜索，LBS的升维效应极大地增加了搜索场景的复杂性。例如对于旅游用户和常驻地用户来说，前者在搜索美食的时候可能会更加关心当地的知名特色商户，而对于距离相对不敏感。  上述的各项特性，叠加上时间、空间、场景等维度，使得点评搜索面临比通用搜索引擎更加独特的挑战。而解决这些挑战的方法，就需要升级NLP（Natural Language Processing，自然语言处理）技术，进行深度查询理解以及深度评价分析，并依赖知识图谱技术和深度学习技术对搜索架构进行整体升级。在美团NLP中心以及大众点评搜索智能中心两个团队的紧密合作之下，经过短短半年时间，点评搜索核心KPI在高位基础上仍然大幅提升，是过去一年半涨幅的六倍之多，提前半年完成全年目标。
基于知识图谱的搜索架构重塑 美团NLP中心正在构建全世界最大的餐饮娱乐知识图谱——美团大脑（相关信息请参见《美团大脑：知识图谱的建模方法及其应用》）。它充分挖掘关联各个场景数据，用NLP技术让机器“阅读”用户公开评论，理解用户在菜品、价格、服务、环境等方面的喜好，构建人、店、商品、场景之间的知识关联，从而形成一个“知识大脑”[1]。通过将知识图谱信息加入到搜索各个流程中，我们对点评搜索的整体架构进行了升级重塑，图1为点评搜索基于知识图谱搭建的5层搜索架构。本篇文章是“美团大脑”系列文章第二篇（系列首篇文章请参见《美团餐饮娱乐知识图谱——美团大脑揭秘》)，主要介绍点评搜索5层架构中核心排序层的演变过程，文章主要分为如下3个部分：
 核心排序从传统机器学习模型到大规模深度学习模型的演进。 搜索场景深度学习排序模型的特征工程实践。 适用于搜索场景的深度学习Listwise排序算法——LambdaDNN。  图1 基于知识图谱的点评搜索5层架构
2. 排序模型探索与实践 搜索排序问题在机器学习领域有一个单独的分支，Learning to Rank（L2R）。主要分类如下:
 根据样本生成方法和Loss Function的不同，L2R可以分为Pointwise、Pairwise、Listwise。 按照模型结构划分，可以分为线性排序模型、树模型、深度学习模型，他们之间的组合（GBDT+LR，Deep&amp;amp;Wide等）。  在排序模型方面，点评搜索也经历了业界比较普遍的迭代过程：从早期的线性模型LR，到引入自动二阶交叉特征的FM和FFM，到非线性树模型GBDT和GBDT+LR，到最近全面迁移至大规模深度学习排序模型。下面先简单介绍下传统机器学习模型（LR、FM、GBDT）的应用和优缺点，然后详细介绍深度模型的探索实践过程。
传统机器学习模型 图2 几种传统机器学习模型结构
 LR可以视作单层单节点的线性网络结构。模型优点是可解释性强。通常而言，良好的解释性是工业界应用实践比较注重的一个指标，它意味着更好的可控性，同时也能指导工程师去分析问题优化模型。但是LR需要依赖大量的人工特征挖掘投入，有限的特征组合自然无法提供较强的表达能力。 FM可以看做是在LR的基础上增加了一部分二阶交叉项。引入自动的交叉特征有助于减少人工挖掘的投入，同时增加模型的非线性，捕捉更多信息。FM能够自动学习两两特征间的关系，但更高量级的特征交叉仍然无法满足。 GBDT是一个Boosting的模型，通过组合多个弱模型逐步拟合残差得到一个强模型。树模型具有天然的优势，能够很好的挖掘组合高阶统计特征，兼具较优的可解释性。GBDT的主要缺陷是依赖连续型的统计特征，对于高维度稀疏特征、时间序列特征不能很好的处理。  深度神经网络模型 随着业务的发展，在传统模型上取得指标收益变得愈发困难。同时业务的复杂性要求我们引入海量用户历史数据，超大规模知识图谱特征等多维度信息源，以实现精准个性化的排序。因此我们从2018年下半年开始，全力推进L2核心排序层的主模型迁移至深度学习排序模型。深度模型优势体现在如下几个方面：
 强大的模型拟合能力：深度学习网络包含多个隐藏层和隐藏结点，配合上非线性的激活函数，理论上可以拟合任何函数，因此十分适用于点评搜索这种复杂的场景。 强大的特征表征和泛化能力：深度学习模型可以处理很多传统模型无法处理的特征。例如深度网络可以直接中从海量训练样本中学习到高维稀疏ID的隐含信息，并通过Embedding的方式去表征；另外对于文本、序列特征以及图像特征，深度网络均有对应的结构或者单元去处理。 自动组合和发现特征的能力：华为提出的DeepFM，以及Google提出的DeepCrossNetwork可以自动进行特征组合，代替大量人工组合特征的工作。  下图是我们基于Google提出的Wide&amp;amp;Deep模型搭建的网络结构[2]。其中Wide部分输入的是LR、GBDT阶段常用的一些细粒度统计特征。通过较长周期统计的高频行为特征，能够提供很好的记忆能力。Deep部分通过深层的神经网络学习Low-Order、高纬度稀疏的Categorical型特征，拟合样本中的长尾部分，发现新的特征组合，提高模型的泛化能力。同时对于文本、头图等传统机器学习模型难以刻画的特征，我们可以通过End-to-End的方式，利用相应的子网络模型进行预处理表示，然后进行融合学习。
图3 Deep&amp;amp;Wide模型结构图
3. 搜索深度排序模型的特征工程实践 深度学习的横空出世，将算法工程师从很多人工挖掘和组合特征的事情中解放出来。甚至有一种论调，专做特征工程的算法工程师可能面临着失业的风险。但是深度学习的自动特征学习目前主要集中体现在CV领域，CV领域的特征数据是图片的像素点——稠密的低阶特征，深度学习通过卷积层这个强力工具，可以自动对低阶特征进行组合和变换，相比之前人工定义的图像特征从效果上来说确实更加显著。在NLP领域因为Transformer的出现，在自动特征挖掘上也有了长足的进步，BERT利用Transformer在多个NLP Task中取得了State-of-The-Art的效果。
但是对于CTR预估和排序学习的领域，目前深度学习尚未在自动特征挖掘上对人工特征工程形成碾压之势，因此人工特征工程依然很重要。当然，深度学习在特征工程上与传统模型的特征工程也存在着一些区别，我们的工作主要集中在如下几个方面。
3.1 特征预处理  特征归一化：深度网络的学习几乎都是基于反向传播，而此类梯度优化的方法对于特征的尺度非常敏感。因此，需要对特征进行归一化或者标准化以促使模型更好的收敛。
 特征离散化：工业界一般很少直接使用连续值作为特征，而是将特征离散化后再输入到模型中。一方面因为离散化特征对于异常值具有更好的鲁棒性，其次可以为特征引入非线性的能力。并且，离散化可以更好的进行Embedding，我们主要使用如下两种离散化方法：
 等频分桶：按样本频率进行等频切分，缺失值可以选择给一个默认桶值或者单独设置分桶。 树模型分桶：等频离散化的方式在特征分布特别不均匀的时候效果往往不好。此时可以利用单特征结合Label训练树模型，以树的分叉点做为切分值，相应的叶子节点作为桶号。  特征组合：基于业务场景对基础特征进行组合，形成更丰富的行为表征，为模型提供先验信息，可加速模型的收敛速度。典型示例如下：
 用户性别与类目之间的交叉特征，能够刻画出不同性别的用户在类目上的偏好差异，比如男性用户可能会较少关注“丽人”相关的商户。 时间与类目之间的交叉特征，能够刻画出不同类目商户在时间上的差异，例如，酒吧在夜间会更容易被点击。   3.</description>
    </item>
    
    <item>
      <title>Elasticsearch面试题解读</title>
      <link>https://argsno.github.com/2019/elasticsearch%E9%9D%A2%E8%AF%95%E9%A2%98%E8%A7%A3%E8%AF%BB/</link>
      <pubDate>Sat, 26 Jan 2019 22:25:10 +0800</pubDate>
      
      <guid>https://argsno.github.com/2019/elasticsearch%E9%9D%A2%E8%AF%95%E9%A2%98%E8%A7%A3%E8%AF%BB/</guid>
      <description>题记 git上发现了网友总结的Elasticsearch BAT大厂面试题。只有题目，部分有答案，但不全。 正好抽出一些时间一起梳理一下。
既然是面试题，每个人都会有自己的结合业务场景的答案，没有非常标准的答案。 欢迎大家留言拍砖指正。
1、elasticsearch了解多少，说说你们公司es的集群架构，索引数据大小，分片有多少，以及一些调优手段 。 面试官：想了解应聘者之前公司接触的ES使用场景、规模，有没有做过比较大规模的索引设计、规划、调优。
解答： 如实结合自己的实践场景回答即可。 比如：ES集群架构13个节点，索引根据通道不同共20+索引，根据日期，每日递增20+，索引：10分片，每日递增1亿+数据， 每个通道每天索引大小控制：150GB之内。
仅索引层面调优手段：
1.1、设计阶段调优
 根据业务增量需求，采取基于日期模板创建索引，通过roll over API滚动索引； 使用别名进行索引管理； 每天凌晨定时对索引做force_merge操作，以释放空间； 采取冷热分离机制，热数据存储到SSD，提高检索效率；冷数据定期进行shrink操作，以缩减存储； 采取curator进行索引的生命周期管理； 仅针对需要分词的字段，合理的设置分词器； Mapping阶段充分结合各个字段的属性，是否需要检索、是否需要存储等。 …  1.2、写入调优
 写入前副本数设置为0； 写入前关闭refresh_interval设置为-1，禁用刷新机制； 写入过程中：采取bulk批量写入； 写入后恢复副本数和刷新间隔； 尽量使用自动生成的id。  1.3、查询调优
 禁用wildcard； 禁用批量terms（成百上千的场景）； 充分利用倒排索引机制，能keyword类型尽量keyword； 数据量大时候，可以先基于时间敲定索引再检索； 设置合理的路由机制。  1.4、其他调优
部署调优，业务调优等。
上面的提及一部分，面试者就基本对你之前的实践或者运维经验有所评估了。
2、elasticsearch的倒排索引是什么？ 面试官：想了解你对基础概念的认知。
解答：通俗解释一下就可以。
传统的我们的检索是通过文章，逐个遍历找到对应关键词的位置。 而倒排索引，是通过分词策略，形成了词和文章的映射关系表，这种词典+映射表即为倒排索引。 有了倒排索引，就能实现o（1）时间复杂度的效率检索文章了，极大的提高了检索效率。
学术的解答方式：
倒排索引，相反于一篇文章包含了哪些词，它从词出发，记载了这个词在哪些文档中出现过，由两部分组成——词典和倒排表。
加分项：倒排索引的底层实现是基于：FST（Finite State Transducer）数据结构。 lucene从4+版本后开始大量使用的数据结构是FST。FST有两个优点：
 空间占用小。通过对词典中单词前缀和后缀的重复利用，压缩了存储空间； 查询速度快。O(len(str))的查询时间复杂度。  3、elasticsearch 索引数据多了怎么办，如何调优，部署？ 面试官：想了解大数据量的运维能力。
解答：索引数据的规划，应在前期做好规划，正所谓“设计先行，编码在后”，这样才能有效的避免突如其来的数据激增导致集群处理能力不足引发的线上客户检索或者其他业务受到影响。 如何调优，正如问题1所说，这里细化一下：
3.1 动态索引层面 基于模板+时间+rollover api滚动创建索引，举例：设计阶段定义：blog索引的模板格式为：blog_index_时间戳的形式，每天递增数据。</description>
    </item>
    
    <item>
      <title>Java GC</title>
      <link>https://argsno.github.com/2017/java-gc/</link>
      <pubDate>Thu, 07 Dec 2017 14:53:43 +0000</pubDate>
      
      <guid>https://argsno.github.com/2017/java-gc/</guid>
      <description>判断对象是否存活 引用计数法 给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值加1；当引用失效时，计数器值减1；任何时刻计数器为0的对象就是还不可能再被使用的。实现简单，判定效率高，但很难解决对象之间相互循环引用的问题。
可达性分析算法 通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。
在Java语言中，可作为GC Roots的对象包括下面几种：
 虚拟机栈（栈帧中的本地变量表）中引用的对象。 方法区中类静态属性引用的对象。 方法区中常量引用的对象。 本地方法栈中JNI（即一般说的Native方法）引用的对象  Java中的引用 Java将引用分为强引用（Strong Reference）、软引用（Soft Reference）、弱引用（Weak Reference）、虚引用（Phantom Reference）4种，这4种引用强度依次逐渐减弱。
 强引用：只要强引用还存在，垃圾收集器永远不会回收被引用的对象。 软引用：在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收，Java中提供了SoftReference类来实现软引用。 弱引用：被弱引用关联的对象只能生存到下一次垃圾收集发生之前。Java中提供了WeakReference类来实现弱引用。 虚引用，也称为幽灵引用或者幻影引用：一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。Java中提供了PhantomReference类来实现虚引用。  finalize方法 如果对象在进行可达性分析之后发现没有与GC Roots相连接的引用链，那它将会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。当对象没有覆盖finalize()方法，或者finalize()方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”。
如果这个对象被判定为有必要执行finalize()方法，那么这个对象将会放置在一个叫做F-Queue的队列之中，并在稍后由一个由虚拟机自动建立的、低优先级的Finalizer线程去执行它。
任何一个对象的finalize()方法都只会被系统自动调用一次，如果对象面临下一次回收，它的finalize()方法不会被再次执行。finalize()能做的所有工作，使用try-finally或者其他方式都可以做得更好、更及时。
垃圾收集算法 标记-清除算法 首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。
它的主要不足有两个：一个是效率问题，标记和清除两个过程的效率都不高；另一个是空间问题，标记清除之后会产生大量不连续的内存碎片。
复制算法 将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活的对象复制到另一快上面，然后再把已使用过的内存一次清理掉。代价是将内存缩小为了原来的一半。
现在的商业虚拟机都采用这种收集算法来回收新生代。但是并不需要按照1:1的比例划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。Hotspot虚拟机默认Eden和Survivor的大小比例是8:1。当Survivor空间不够用时，需要依赖其他内存（这里指老年代）进行分配担保。
标记-整理算法 根据老年代的特点，标记-整理算法的标记过程仍然与标记-清除算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一边移动，然后直接清理掉端边界以外的内存。
分代收集算法 一般把Java堆分成新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。
垃圾收集器 Serial收集器 单线程的收集器，并且在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。新生代收集器。复制算法。
ParNew收集器 Serial收集器的多线程版本。新生代收集器。复制算法。
Parallel Scavenge收集器 新生代收集器。复制算法。并行的多线程收集器。Parallel Scavenge收集器的目的则是达到一个可控制的吞吐量。提供了两个参数用于精确控制吞吐量，分别是控制最大垃圾收集停顿时间的-XX:MaxGCPauseMillis参数以及直接设置吞吐量大小的-XX:GCTimeRatio参数。
Serial Old收集器 Serial收集器的老年代版本，单线程，使用标记-整理算法。
Parallel Old收集器 Parallel Scavenge收集器的老年代版本，使用多线程和“标记-整理”算法。
CMS（Concurrent Mark Sweep）收集器 以获取最短回收停顿时间为目标的收集器。CMS收集器是基于“标记-清除”算法实现的，包括以下4个步骤：
 初始标记（CMS initial mark） 并发标记（CMS concurrent mark） 重新标记（CMS remark） 并发清除（CMS concurrent sweep） 其中，初始标记、重新标记这两个步骤仍然需要“Stop The World”。初始标记仅仅是标记一下GC Roots能直接关联到的对象，速度很快；并发标记阶段就是进行GC Roots Tracing的过程；而重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。  G1收集器 特点：</description>
    </item>
    
    <item>
      <title>Java ClassLoader</title>
      <link>https://argsno.github.com/2017/java-classloader/</link>
      <pubDate>Wed, 06 Dec 2017 11:29:51 +0000</pubDate>
      
      <guid>https://argsno.github.com/2017/java-classloader/</guid>
      <description> 类加载的时机 类的整个生命周期包括：加载（Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化（Initialization）、使用（Using）和卸载（Unloading）7个阶段。其中验证、准备、解析3个部分统称为连接（Linking）。
虚拟机规范中严格规定了有且只有5种情况必须立即对类进行“初始化”：
 遇到new、getstatic、putstatic和invokestatic这4条字节码指令时，如果类没有进行过初始化，则需要触发其初始化。常见的Java代码场景：使用new关键字实例化对象的时候、读取或设置一个类的静态字段（被final修饰、已在编译器把结果放入常量池的静态字段除外）的时候，以及调用一个类的静态方法的时候。
 使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。
 当初始化一个类的时候，如果发现其父类还没有初始化，则需要先触发其父类的初始化。
 当虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始化这个主类。
 当使用JDK 1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。
  这5种场景中的行为称为对一个类进行主动调用。除此之外，所有引用类的方式都不会触发初始化，称为被动引用。被动引用包括：
 通过子类引用父类的静态字段，不会导致子类初始化。 通过数组定义来引用类，不会触发类的初始化。 常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化。  接口与类真正有所区别的初始化场景：在一个接口初始化时，并不要求其父接口全部都完成了初始化，只有在真正使用到父接口的时候（如引用接口中定义的常量）才会初始化。
类加载的过程 加载 在加载阶段，虚拟机需要完成一下3件事情：
 通过一个类的全限定名来获取此类的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。  验证 验证是连接阶段的第一步。这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害自身的安全。 验证阶段大致会完成下面4个阶段的检验动作：文件格式验证、元数据验证、字节码验证、符号引用验证。文件格式验证是基于二进制字节流进行的，后面的3个验证阶段全部是基于方法区的存储结构进行的。
 文件格式验证：验证字节流是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理。 元数据验证：对字节码描述的信息进行语义分析，已保证其描述的信息符合Java语言规范的要求。 字节码验证：通过数据流和控制流分析，确保程序语义是合法的、符合逻辑的。 符号引用验证：可以看做是对类自身以外（常量池中的各种符号引用）的信息进行匹配性校验。  准备 准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。
解析 解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。
初始化 初始化阶段是执行类构造器&amp;lt;clinit&amp;gt;()方法的过程。
类加载器 类与类加载器 类加载器只用于实现类的加载动作。对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在Java虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。
双亲委派模型 从Java虚拟机的角度来讲，只存在两种不同的类加载器：一种是启动类加载器（Bootstrap ClassLoader），是虚拟机自身的一部分；另一种就是所有其他的类加载器，这些类加载器都由Java语言实现，独立于虚拟机外部，并且全都继承自抽象类java.lang.ClassLoader。
从Java开发人员的角度来看，类加载器还可以划分得更细致一些，绝大部分Java程序都会使用到以下3中系统提供的类加载器。
 启动类加载器：这个类加载器负责存放在/lib目录中的，或者被-Xbootclasspath参数所指定的路径中的，并且是虚拟机识别的类库加载到虚拟机内存中。启动类加载器无法被Java程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给引导类加载器，那直接使用null代替即可。 扩展类加载器（Extension ClassLoader）：这个类加载器有sun.misc.Launcher$ExtClassLoader实现，它负责加载/lib/ext目录中的，或者被java.ext.dirs系统变量所指定的路径中的所有类库。开发者可以直接使用扩展类加载器。 应用程序类加载器（Application ClassLoader）：这个类加载器由sun.misc.Launcher$AppClassLoader实现。它负责加载用户类路径（ClassPath）上所指定的类库。开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类机载器，一般情况下这个就是程序中默认的类加载器。  </description>
    </item>
    
    <item>
      <title>Java 运行时数据区域</title>
      <link>https://argsno.github.com/2017/java-runtime-data/</link>
      <pubDate>Tue, 05 Dec 2017 10:33:17 +0000</pubDate>
      
      <guid>https://argsno.github.com/2017/java-runtime-data/</guid>
      <description>程序计数器 当前线程所执行的字节码的行号指示器，用于记录下一条要执行的指令。每个线程都需要有一个独立的程序计数器，线程私有。 如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Native方法，这个计数器值则为空（Undefined）。
此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。
Java虚拟机栈 线程私有，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。局部变量表中存放了编译器可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型）和returnAddress类型（指向了一条字节码指令的地址）。其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。局部变量表所需的内存空间在编译期间完成分配，在方法运行期间不会改变局部变量表的大小。
两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机栈可以动态扩展，如果扩展时无法申请到足够的内存，就会抛出OutOfMemoryError异常。
本地方法栈 与虚拟机栈相似，只不过是为虚拟机所用到的Native方法服务。
Java堆 Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建，用于存放对象实例。可以通过-Xmx和-Xms控制大小。
如果在堆中没有内存完成实例分配，并且堆也无法在扩展时，将会抛出OutOfMemoryError异常。
方法区 各个线程共享的内存区域。用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。这区域的内存回收目标主要针对常量池的回收和对类型的卸载。
当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。
运行时常量池 运行时常量池是方法区的一部分。用于存放Class文件中的常量池以及在运行期间可能将新的常量放入池中。
当常量池无法再申请内存时会抛出OutOfMemoryError异常。
直接内存 不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域。在NIO中通过避免在Java堆和Native堆中来回复制数据显著提高性能。
经常被忽略导致可能动态扩展时出现OutOfMemoryError异常。</description>
    </item>
    
  </channel>
</rss>
<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ArgsNo&#39;s Notes on ArgsNo&#39;s Notes</title>
    <link>https://argsno.github.com/</link>
    <description>Recent content in ArgsNo&#39;s Notes on ArgsNo&#39;s Notes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 26 Jan 2019 22:25:10 +0800</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Elasticsearch面试题解读</title>
      <link>https://argsno.github.com/2019/elasticsearch%E9%9D%A2%E8%AF%95%E9%A2%98%E8%A7%A3%E8%AF%BB/</link>
      <pubDate>Sat, 26 Jan 2019 22:25:10 +0800</pubDate>
      
      <guid>https://argsno.github.com/2019/elasticsearch%E9%9D%A2%E8%AF%95%E9%A2%98%E8%A7%A3%E8%AF%BB/</guid>
      <description>

&lt;h2 id=&#34;题记&#34;&gt;题记&lt;/h2&gt;

&lt;p&gt;git上发现了网友总结的Elasticsearch BAT大厂面试题。只有题目，部分有答案，但不全。 正好抽出一些时间一起梳理一下。&lt;/p&gt;

&lt;p&gt;既然是面试题，每个人都会有自己的结合业务场景的答案，没有非常标准的答案。
欢迎大家留言拍砖指正。&lt;/p&gt;

&lt;h2 id=&#34;1-elasticsearch了解多少-说说你们公司es的集群架构-索引数据大小-分片有多少-以及一些调优手段&#34;&gt;1、elasticsearch了解多少，说说你们公司es的集群架构，索引数据大小，分片有多少，以及一些调优手段 。&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;面试官&lt;/strong&gt;：想了解应聘者之前公司接触的ES使用场景、规模，有没有做过比较大规模的索引设计、规划、调优。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;解答&lt;/strong&gt;：
如实结合自己的实践场景回答即可。
比如：ES集群架构13个节点，索引根据通道不同共20+索引，根据日期，每日递增20+，索引：10分片，每日递增1亿+数据，
每个通道每天索引大小控制：150GB之内。&lt;/p&gt;

&lt;p&gt;仅索引层面调优手段：&lt;/p&gt;

&lt;p&gt;1.1、设计阶段调优&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;根据业务增量需求，采取基于日期模板创建索引，通过roll over API滚动索引；&lt;/li&gt;
&lt;li&gt;使用别名进行索引管理；&lt;/li&gt;
&lt;li&gt;每天凌晨定时对索引做force_merge操作，以释放空间；&lt;/li&gt;
&lt;li&gt;采取冷热分离机制，热数据存储到SSD，提高检索效率；冷数据定期进行shrink操作，以缩减存储；&lt;/li&gt;
&lt;li&gt;采取curator进行索引的生命周期管理；&lt;/li&gt;
&lt;li&gt;仅针对需要分词的字段，合理的设置分词器；&lt;/li&gt;
&lt;li&gt;Mapping阶段充分结合各个字段的属性，是否需要检索、是否需要存储等。 …&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;1.2、写入调优&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;写入前副本数设置为0；&lt;/li&gt;
&lt;li&gt;写入前关闭refresh_interval设置为-1，禁用刷新机制；&lt;/li&gt;
&lt;li&gt;写入过程中：采取bulk批量写入；&lt;/li&gt;
&lt;li&gt;写入后恢复副本数和刷新间隔；&lt;/li&gt;
&lt;li&gt;尽量使用自动生成的id。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;1.3、查询调优&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;禁用wildcard；&lt;/li&gt;
&lt;li&gt;禁用批量terms（成百上千的场景）；&lt;/li&gt;
&lt;li&gt;充分利用倒排索引机制，能keyword类型尽量keyword；&lt;/li&gt;
&lt;li&gt;数据量大时候，可以先基于时间敲定索引再检索；&lt;/li&gt;
&lt;li&gt;设置合理的路由机制。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;1.4、其他调优&lt;/p&gt;

&lt;p&gt;部署调优，业务调优等。&lt;/p&gt;

&lt;p&gt;上面的提及一部分，面试者就基本对你之前的实践或者运维经验有所评估了。&lt;/p&gt;

&lt;h2 id=&#34;2-elasticsearch的倒排索引是什么&#34;&gt;2、elasticsearch的倒排索引是什么？&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;面试官&lt;/strong&gt;：想了解你对基础概念的认知。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;解答&lt;/strong&gt;：通俗解释一下就可以。&lt;/p&gt;

&lt;p&gt;传统的我们的检索是通过文章，逐个遍历找到对应关键词的位置。
而倒排索引，是通过分词策略，形成了词和文章的映射关系表，这种词典+映射表即为倒排索引。
有了倒排索引，就能实现o（1）时间复杂度的效率检索文章了，极大的提高了检索效率。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ws2.sinaimg.cn/large/006tNc79ly1fzkd4imut4j305d058mx7.jpg&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;p&gt;学术的解答方式：&lt;/p&gt;

&lt;p&gt;倒排索引，相反于一篇文章包含了哪些词，它从词出发，记载了这个词在哪些文档中出现过，由两部分组成——词典和倒排表。&lt;/p&gt;

&lt;p&gt;加分项：倒排索引的底层实现是基于：FST（Finite State Transducer）数据结构。
lucene从4+版本后开始大量使用的数据结构是FST。FST有两个优点：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;空间占用小。通过对词典中单词前缀和后缀的重复利用，压缩了存储空间；&lt;/li&gt;
&lt;li&gt;查询速度快。O(len(str))的查询时间复杂度。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;3-elasticsearch-索引数据多了怎么办-如何调优-部署&#34;&gt;3、elasticsearch 索引数据多了怎么办，如何调优，部署？&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;面试官&lt;/strong&gt;：想了解大数据量的运维能力。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;解答&lt;/strong&gt;：索引数据的规划，应在前期做好规划，正所谓“设计先行，编码在后”，这样才能有效的避免突如其来的数据激增导致集群处理能力不足引发的线上客户检索或者其他业务受到影响。
如何调优，正如问题1所说，这里细化一下：&lt;/p&gt;

&lt;h3 id=&#34;3-1-动态索引层面&#34;&gt;3.1 动态索引层面&lt;/h3&gt;

&lt;p&gt;基于&lt;code&gt;模板+时间+rollover api滚动&lt;/code&gt;创建索引，举例：设计阶段定义：blog索引的模板格式为：blog_index_时间戳的形式，每天递增数据。&lt;/p&gt;

&lt;p&gt;这样做的好处：不至于数据量激增导致单个索引数据量非常大，接近于上线2的32次幂-1，索引存储达到了TB+甚至更大。&lt;/p&gt;

&lt;p&gt;一旦单个索引很大，存储等各种风险也随之而来，所以要提前考虑+及早避免。&lt;/p&gt;

&lt;h3 id=&#34;3-2-存储层面&#34;&gt;3.2 存储层面&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;冷热数据分离存储&lt;/code&gt;，热数据（比如最近3天或者一周的数据），其余为冷数据。
对于冷数据不会再写入新数据，可以考虑定期force_merge加shrink压缩操作，节省存储空间和检索效率。&lt;/p&gt;

&lt;h3 id=&#34;3-3-部署层面&#34;&gt;3.3 部署层面&lt;/h3&gt;

&lt;p&gt;一旦之前没有规划，这里就属于应急策略。
结合ES自身的支持动态扩展的特点，动态新增机器的方式可以缓解集群压力，注意：如果之前主节点等规划合理，不需要重启集群也能完成动态新增的。&lt;/p&gt;

&lt;h2 id=&#34;4-elasticsearch是如何实现master选举的&#34;&gt;4、elasticsearch是如何实现master选举的？&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;面试官&lt;/strong&gt;：想了解ES集群的底层原理，不再只关注业务层面了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;解答&lt;/strong&gt;：
前置前提：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;只有候选主节点（master：true）的节点才能成为主节点。&lt;/li&gt;
&lt;li&gt;最小主节点数（min_master_nodes）的目的是防止脑裂。
这个我看了各种网上分析的版本和源码分析的书籍，云里雾里。
核对了一下代码，核心入口为findMaster，选择主节点成功返回对应Master，否则返回null。选举流程大致描述如下：&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;第一步：确认候选主节点数达标，elasticsearch.yml设置的值discovery.zen.minimum_master_nodes；
第二步：比较：先判定是否具备master资格，具备候选主节点资格的优先返回；若两节点都为候选主节点，则id小的值会主节点。注意这里的id为string类型。
题外话：获取节点id的方法。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-curl&#34;&gt;GET /_cat/nodes?v&amp;amp;h=ip,port,heapPercent,heapMax,id,name
ip        port heapPercent heapMax id   name
127.0.0.1 9300          39   1.9gb Hk9w Hk9wFwU
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;5-详细描述一下elasticsearch索引文档的过程&#34;&gt;5、详细描述一下Elasticsearch索引文档的过程？&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;面试官&lt;/strong&gt;：想了解ES的底层原理，不再只关注业务层面了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;解答&lt;/strong&gt;：
这里的索引文档应该理解为文档写入ES，创建索引的过程。
文档写入包含：单文档写入和批量bulk写入，这里只解释一下：单文档写入流程。&lt;/p&gt;

&lt;p&gt;记住官方文档中的这个图。&lt;/p&gt;

&lt;p&gt;第一步：客户写集群某节点写入数据，发送请求。（如果没有指定路由/协调节点，请求的节点扮演路由节点的角色。）&lt;/p&gt;

&lt;p&gt;第二步：节点1接受到请求后，使用文档_id来确定文档属于分片0。请求会被转到另外的节点，假定节点3。因此分片0的主分片分配到节点3上。&lt;/p&gt;

&lt;p&gt;第三步：节点3在主分片上执行写操作，如果成功，则将请求并行转发到节点1和节点2的副本分片上，等待结果返回。所有的副本分片都报告成功，节点3将向协调节点（节点1）报告成功，节点1向请求客户端报告写入成功。&lt;/p&gt;

&lt;p&gt;如果面试官再问：第二步中的文档获取分片的过程？
回答：借助路由算法获取，路由算法就是根据路由和文档id计算目标的分片id的过程。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-math&#34;&gt;shard = hash(_routing) % (num_of_primary_shards)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;6-详细描述一下elasticsearch搜索的过程&#34;&gt;6、详细描述一下Elasticsearch搜索的过程？&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;面试官&lt;/strong&gt;：想了解ES搜索的底层原理，不再只关注业务层面了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;解答&lt;/strong&gt;：
搜索拆解为“query then fetch” 两个阶段。
query阶段的目的：定位到位置，但不取。
步骤拆解如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;假设一个索引数据有5主+1副本 共10分片，一次请求会命中（主或者副本分片中）的一个。&lt;/li&gt;
&lt;li&gt;每个分片在本地进行查询，结果返回到本地有序的优先队列中。&lt;/li&gt;
&lt;li&gt;第2步骤的结果发送到协调节点，协调节点产生一个全局的排序列表。
fetch阶段的目的：取数据。
路由节点获取所有文档，返回给客户端。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;7-elasticsearch在部署时-对linux的设置有哪些优化方法&#34;&gt;7、Elasticsearch在部署时，对Linux的设置有哪些优化方法？&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;面试官&lt;/strong&gt;：想了解对ES集群的运维能力。
&lt;strong&gt;解答&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;关闭缓存swap;&lt;/li&gt;
&lt;li&gt;堆内存设置为：Min（节点内存/2, 32GB）;&lt;/li&gt;
&lt;li&gt;设置最大文件句柄数；&lt;/li&gt;
&lt;li&gt;线程池+队列大小根据业务需要做调整；&lt;/li&gt;
&lt;li&gt;磁盘存储raid方式——存储有条件使用RAID10，增加单节点性能以及避免单节点存储故障。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;8-lucence内部结构是什么&#34;&gt;8、lucence内部结构是什么？&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;面试官&lt;/strong&gt;：想了解你的知识面的广度和深度。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;解答&lt;/strong&gt;：
&lt;img src=&#34;https://ws3.sinaimg.cn/large/006tNc79ly1fzkd69t7wvj30ft0d9dic.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Lucene是有索引和搜索的两个过程，包含索引创建，索引，搜索三个要点。可以基于这个脉络展开一些。&lt;/p&gt;

&lt;h2 id=&#34;小结&#34;&gt;小结&lt;/h2&gt;

&lt;p&gt;看到题目后，感觉熟悉又陌生。真正要在面试的时候讲出来，需要下一番功夫深入理解。
为了求证回答的相对准确性，我翻看了源码、官方文档和部分有深度的博文。
Elasticsearch路还很长，别无他法，唯有死磕！&lt;/p&gt;

&lt;p&gt;题目来源：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/randian666/algorithm-study#搜索&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://github.com/randian666/algorithm-study#搜索&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cnblogs.com/luckcs/articles/7052932.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://www.cnblogs.com/luckcs/articles/7052932.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;核心参考：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cnblogs.com/LBSer/p/4119841.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;http://www.cnblogs.com/LBSer/p/4119841.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/njpjsoftdev/article/details/54015485&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://blog.csdn.net/njpjsoftdev/article/details/54015485&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://elasticsearch.cn/book/elasticsearch_definitive_guide_2.x/distrib-write.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://elasticsearch.cn/book/elasticsearch_definitive_guide_2.x/distrib-write.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cnblogs.com/forfuture1978/archive/2010/05/19/1738806.html&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;http://www.cnblogs.com/forfuture1978/archive/2010/05/19/1738806.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;《Elasticsearch源码解析和优化实践》&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Java GC</title>
      <link>https://argsno.github.com/2017/java-gc/</link>
      <pubDate>Thu, 07 Dec 2017 14:53:43 +0000</pubDate>
      
      <guid>https://argsno.github.com/2017/java-gc/</guid>
      <description>

&lt;h2 id=&#34;判断对象是否存活&#34;&gt;判断对象是否存活&lt;/h2&gt;

&lt;h3 id=&#34;引用计数法&#34;&gt;引用计数法&lt;/h3&gt;

&lt;p&gt;给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值加1；当引用失效时，计数器值减1；任何时刻计数器为0的对象就是还不可能再被使用的。实现简单，判定效率高，但很难解决对象之间相互循环引用的问题。&lt;/p&gt;

&lt;h3 id=&#34;可达性分析算法&#34;&gt;可达性分析算法&lt;/h3&gt;

&lt;p&gt;通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。&lt;/p&gt;

&lt;p&gt;在Java语言中，可作为GC Roots的对象包括下面几种：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;虚拟机栈（栈帧中的本地变量表）中引用的对象。&lt;/li&gt;
&lt;li&gt;方法区中类静态属性引用的对象。&lt;/li&gt;
&lt;li&gt;方法区中常量引用的对象。&lt;/li&gt;
&lt;li&gt;本地方法栈中JNI（即一般说的Native方法）引用的对象&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;java中的引用&#34;&gt;Java中的引用&lt;/h3&gt;

&lt;p&gt;Java将引用分为强引用（Strong Reference）、软引用（Soft Reference）、弱引用（Weak Reference）、虚引用（Phantom Reference）4种，这4种引用强度依次逐渐减弱。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;强引用：只要强引用还存在，垃圾收集器永远不会回收被引用的对象。&lt;/li&gt;
&lt;li&gt;软引用：在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收，Java中提供了SoftReference类来实现软引用。&lt;/li&gt;
&lt;li&gt;弱引用：被弱引用关联的对象只能生存到下一次垃圾收集发生之前。Java中提供了WeakReference类来实现弱引用。&lt;/li&gt;
&lt;li&gt;虚引用，也称为幽灵引用或者幻影引用：一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。Java中提供了PhantomReference类来实现虚引用。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;finalize方法&#34;&gt;finalize方法&lt;/h3&gt;

&lt;p&gt;如果对象在进行可达性分析之后发现没有与GC Roots相连接的引用链，那它将会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。当对象没有覆盖finalize()方法，或者finalize()方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”。&lt;/p&gt;

&lt;p&gt;如果这个对象被判定为有必要执行finalize()方法，那么这个对象将会放置在一个叫做F-Queue的队列之中，并在稍后由一个由虚拟机自动建立的、低优先级的Finalizer线程去执行它。&lt;/p&gt;

&lt;p&gt;任何一个对象的finalize()方法都只会被系统自动调用一次，如果对象面临下一次回收，它的finalize()方法不会被再次执行。finalize()能做的所有工作，使用try-finally或者其他方式都可以做得更好、更及时。&lt;/p&gt;

&lt;h2 id=&#34;垃圾收集算法&#34;&gt;垃圾收集算法&lt;/h2&gt;

&lt;h3 id=&#34;标记-清除算法&#34;&gt;标记-清除算法&lt;/h3&gt;

&lt;p&gt;首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。&lt;/p&gt;

&lt;p&gt;它的主要不足有两个：一个是效率问题，标记和清除两个过程的效率都不高；另一个是空间问题，标记清除之后会产生大量不连续的内存碎片。&lt;/p&gt;

&lt;h3 id=&#34;复制算法&#34;&gt;复制算法&lt;/h3&gt;

&lt;p&gt;将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活的对象复制到另一快上面，然后再把已使用过的内存一次清理掉。代价是将内存缩小为了原来的一半。&lt;/p&gt;

&lt;p&gt;现在的商业虚拟机都采用这种收集算法来回收新生代。但是并不需要按照1:1的比例划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。Hotspot虚拟机默认Eden和Survivor的大小比例是8:1。当Survivor空间不够用时，需要依赖其他内存（这里指老年代）进行分配担保。&lt;/p&gt;

&lt;h3 id=&#34;标记-整理算法&#34;&gt;标记-整理算法&lt;/h3&gt;

&lt;p&gt;根据老年代的特点，标记-整理算法的标记过程仍然与标记-清除算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一边移动，然后直接清理掉端边界以外的内存。&lt;/p&gt;

&lt;h3 id=&#34;分代收集算法&#34;&gt;分代收集算法&lt;/h3&gt;

&lt;p&gt;一般把Java堆分成新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。&lt;/p&gt;

&lt;h2 id=&#34;垃圾收集器&#34;&gt;垃圾收集器&lt;/h2&gt;

&lt;h3 id=&#34;serial收集器&#34;&gt;Serial收集器&lt;/h3&gt;

&lt;p&gt;单线程的收集器，并且在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。新生代收集器。复制算法。&lt;/p&gt;

&lt;h3 id=&#34;parnew收集器&#34;&gt;ParNew收集器&lt;/h3&gt;

&lt;p&gt;Serial收集器的多线程版本。新生代收集器。复制算法。&lt;/p&gt;

&lt;h3 id=&#34;parallel-scavenge收集器&#34;&gt;Parallel Scavenge收集器&lt;/h3&gt;

&lt;p&gt;新生代收集器。复制算法。并行的多线程收集器。Parallel Scavenge收集器的目的则是达到一个可控制的吞吐量。提供了两个参数用于精确控制吞吐量，分别是控制最大垃圾收集停顿时间的-XX:MaxGCPauseMillis参数以及直接设置吞吐量大小的-XX:GCTimeRatio参数。&lt;/p&gt;

&lt;h3 id=&#34;serial-old收集器&#34;&gt;Serial Old收集器&lt;/h3&gt;

&lt;p&gt;Serial收集器的老年代版本，单线程，使用标记-整理算法。&lt;/p&gt;

&lt;h3 id=&#34;parallel-old收集器&#34;&gt;Parallel Old收集器&lt;/h3&gt;

&lt;p&gt;Parallel Scavenge收集器的老年代版本，使用多线程和“标记-整理”算法。&lt;/p&gt;

&lt;h3 id=&#34;cms-concurrent-mark-sweep-收集器&#34;&gt;CMS（Concurrent Mark Sweep）收集器&lt;/h3&gt;

&lt;p&gt;以获取最短回收停顿时间为目标的收集器。CMS收集器是基于“标记-清除”算法实现的，包括以下4个步骤：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;初始标记（CMS initial mark）&lt;/li&gt;
&lt;li&gt;并发标记（CMS concurrent mark）&lt;/li&gt;
&lt;li&gt;重新标记（CMS remark）&lt;/li&gt;
&lt;li&gt;并发清除（CMS concurrent sweep）
其中，初始标记、重新标记这两个步骤仍然需要“Stop The World”。初始标记仅仅是标记一下GC Roots能直接关联到的对象，速度很快；并发标记阶段就是进行GC Roots Tracing的过程；而重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;g1收集器&#34;&gt;G1收集器&lt;/h3&gt;

&lt;p&gt;特点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;并行与并发：G1能充分利用多CPU、多核环境下的硬件优势。&lt;/li&gt;
&lt;li&gt;分代收集：G1可以不需要其他收集器配合就能独立管理整个GC堆。&lt;/li&gt;
&lt;li&gt;空间整合：G1从整体来看是基于“标记-整理”算法实现的收集器。&lt;/li&gt;
&lt;li&gt;可预测的停顿：G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;将整个Java堆划分为多个大小相等的独立区域（Region），跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region。&lt;/p&gt;

&lt;p&gt;步骤：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;初始标记（Initial Marking）&lt;/li&gt;
&lt;li&gt;并发标记（Concurrent Marking）&lt;/li&gt;
&lt;li&gt;最终标记（Final Marking）&lt;/li&gt;
&lt;li&gt;筛选回收（Live Data Counting and Evacuation）&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Java ClassLoader</title>
      <link>https://argsno.github.com/2017/java-classloader/</link>
      <pubDate>Wed, 06 Dec 2017 11:29:51 +0000</pubDate>
      
      <guid>https://argsno.github.com/2017/java-classloader/</guid>
      <description>

&lt;h2 id=&#34;类加载的时机&#34;&gt;类加载的时机&lt;/h2&gt;

&lt;p&gt;类的整个生命周期包括：加载（Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化（Initialization）、使用（Using）和卸载（Unloading）7个阶段。其中验证、准备、解析3个部分统称为连接（Linking）。&lt;/p&gt;

&lt;p&gt;虚拟机规范中严格规定了有且只有5种情况必须立即对类进行“初始化”：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;遇到new、getstatic、putstatic和invokestatic这4条字节码指令时，如果类没有进行过初始化，则需要触发其初始化。常见的Java代码场景：使用new关键字实例化对象的时候、读取或设置一个类的静态字段（被final修饰、已在编译器把结果放入常量池的静态字段除外）的时候，以及调用一个类的静态方法的时候。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;当初始化一个类的时候，如果发现其父类还没有初始化，则需要先触发其父类的初始化。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;当虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始化这个主类。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;当使用JDK 1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这5种场景中的行为称为对一个类进行主动调用。除此之外，所有引用类的方式都不会触发初始化，称为被动引用。被动引用包括：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;通过子类引用父类的静态字段，不会导致子类初始化。&lt;/li&gt;
&lt;li&gt;通过数组定义来引用类，不会触发类的初始化。&lt;/li&gt;
&lt;li&gt;常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;接口与类真正有所区别的初始化场景：在一个接口初始化时，并不要求其父接口全部都完成了初始化，只有在真正使用到父接口的时候（如引用接口中定义的常量）才会初始化。&lt;/p&gt;

&lt;h2 id=&#34;类加载的过程&#34;&gt;类加载的过程&lt;/h2&gt;

&lt;h3 id=&#34;加载&#34;&gt;加载&lt;/h3&gt;

&lt;p&gt;在加载阶段，虚拟机需要完成一下3件事情：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;通过一个类的全限定名来获取此类的二进制字节流。&lt;/li&gt;
&lt;li&gt;将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。&lt;/li&gt;
&lt;li&gt;在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;验证&#34;&gt;验证&lt;/h3&gt;

&lt;p&gt;验证是连接阶段的第一步。这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害自身的安全。
验证阶段大致会完成下面4个阶段的检验动作：文件格式验证、元数据验证、字节码验证、符号引用验证。文件格式验证是基于二进制字节流进行的，后面的3个验证阶段全部是基于方法区的存储结构进行的。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;文件格式验证：验证字节流是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理。&lt;/li&gt;
&lt;li&gt;元数据验证：对字节码描述的信息进行语义分析，已保证其描述的信息符合Java语言规范的要求。&lt;/li&gt;
&lt;li&gt;字节码验证：通过数据流和控制流分析，确保程序语义是合法的、符合逻辑的。&lt;/li&gt;
&lt;li&gt;符号引用验证：可以看做是对类自身以外（常量池中的各种符号引用）的信息进行匹配性校验。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;准备&#34;&gt;准备&lt;/h3&gt;

&lt;p&gt;准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。&lt;/p&gt;

&lt;h3 id=&#34;解析&#34;&gt;解析&lt;/h3&gt;

&lt;p&gt;解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。&lt;/p&gt;

&lt;h3 id=&#34;初始化&#34;&gt;初始化&lt;/h3&gt;

&lt;p&gt;初始化阶段是执行类构造器&lt;code&gt;&amp;lt;clinit&amp;gt;()&lt;/code&gt;方法的过程。&lt;/p&gt;

&lt;h2 id=&#34;类加载器&#34;&gt;类加载器&lt;/h2&gt;

&lt;h3 id=&#34;类与类加载器&#34;&gt;类与类加载器&lt;/h3&gt;

&lt;p&gt;类加载器只用于实现类的加载动作。对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在Java虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。&lt;/p&gt;

&lt;h3 id=&#34;双亲委派模型&#34;&gt;双亲委派模型&lt;/h3&gt;

&lt;p&gt;从Java虚拟机的角度来讲，只存在两种不同的类加载器：一种是启动类加载器（Bootstrap ClassLoader），是虚拟机自身的一部分；另一种就是所有其他的类加载器，这些类加载器都由Java语言实现，独立于虚拟机外部，并且全都继承自抽象类java.lang.ClassLoader。&lt;/p&gt;

&lt;p&gt;从Java开发人员的角度来看，类加载器还可以划分得更细致一些，绝大部分Java程序都会使用到以下3中系统提供的类加载器。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;启动类加载器：这个类加载器负责存放在&lt;JAVA_HOME&gt;/lib目录中的，或者被-Xbootclasspath参数所指定的路径中的，并且是虚拟机识别的类库加载到虚拟机内存中。启动类加载器无法被Java程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给引导类加载器，那直接使用null代替即可。&lt;/li&gt;
&lt;li&gt;扩展类加载器（Extension ClassLoader）：这个类加载器有sun.misc.Launcher$ExtClassLoader实现，它负责加载&lt;JAVA_HOME&gt;/lib/ext目录中的，或者被java.ext.dirs系统变量所指定的路径中的所有类库。开发者可以直接使用扩展类加载器。&lt;/li&gt;
&lt;li&gt;应用程序类加载器（Application ClassLoader）：这个类加载器由sun.misc.Launcher$AppClassLoader实现。它负责加载用户类路径（ClassPath）上所指定的类库。开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类机载器，一般情况下这个就是程序中默认的类加载器。&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Java 运行时数据区域</title>
      <link>https://argsno.github.com/2017/java-runtime-data/</link>
      <pubDate>Tue, 05 Dec 2017 10:33:17 +0000</pubDate>
      
      <guid>https://argsno.github.com/2017/java-runtime-data/</guid>
      <description>

&lt;h2 id=&#34;程序计数器&#34;&gt;程序计数器&lt;/h2&gt;

&lt;p&gt;当前线程所执行的字节码的行号指示器，用于记录下一条要执行的指令。每个线程都需要有一个独立的程序计数器，线程私有。
如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Native方法，这个计数器值则为空（Undefined）。&lt;/p&gt;

&lt;p&gt;此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。&lt;/p&gt;

&lt;h2 id=&#34;java虚拟机栈&#34;&gt;Java虚拟机栈&lt;/h2&gt;

&lt;p&gt;线程私有，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。局部变量表中存放了编译器可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型）和returnAddress类型（指向了一条字节码指令的地址）。其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。局部变量表所需的内存空间在编译期间完成分配，在方法运行期间不会改变局部变量表的大小。&lt;/p&gt;

&lt;p&gt;两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机栈可以动态扩展，如果扩展时无法申请到足够的内存，就会抛出OutOfMemoryError异常。&lt;/p&gt;

&lt;h2 id=&#34;本地方法栈&#34;&gt;本地方法栈&lt;/h2&gt;

&lt;p&gt;与虚拟机栈相似，只不过是为虚拟机所用到的Native方法服务。&lt;/p&gt;

&lt;h2 id=&#34;java堆&#34;&gt;Java堆&lt;/h2&gt;

&lt;p&gt;Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建，用于存放对象实例。可以通过-Xmx和-Xms控制大小。&lt;/p&gt;

&lt;p&gt;如果在堆中没有内存完成实例分配，并且堆也无法在扩展时，将会抛出OutOfMemoryError异常。&lt;/p&gt;

&lt;h2 id=&#34;方法区&#34;&gt;方法区&lt;/h2&gt;

&lt;p&gt;各个线程共享的内存区域。用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。这区域的内存回收目标主要针对常量池的回收和对类型的卸载。&lt;/p&gt;

&lt;p&gt;当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。&lt;/p&gt;

&lt;h2 id=&#34;运行时常量池&#34;&gt;运行时常量池&lt;/h2&gt;

&lt;p&gt;运行时常量池是方法区的一部分。用于存放Class文件中的常量池以及在运行期间可能将新的常量放入池中。&lt;/p&gt;

&lt;p&gt;当常量池无法再申请内存时会抛出OutOfMemoryError异常。&lt;/p&gt;

&lt;h2 id=&#34;直接内存&#34;&gt;直接内存&lt;/h2&gt;

&lt;p&gt;不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域。在NIO中通过避免在Java堆和Native堆中来回复制数据显著提高性能。&lt;/p&gt;

&lt;p&gt;经常被忽略导致可能动态扩展时出现OutOfMemoryError异常。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://argsno.github.com/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://argsno.github.com/about/</guid>
      <description>&lt;p&gt;Hugo is the &lt;strong&gt;world’s fastest framework for building websites&lt;/strong&gt;. It is written in Go.&lt;/p&gt;

&lt;p&gt;It makes use of a variety of open source projects including:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/russross/blackfriday&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://github.com/russross/blackfriday&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/alecthomas/chroma&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://github.com/alecthomas/chroma&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/muesli/smartcrop&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://github.com/muesli/smartcrop&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spf13/cobra&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://github.com/spf13/cobra&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spf13/viper&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;https://github.com/spf13/viper&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Learn more and contribute on &lt;a href=&#34;https://github.com/gohugoio&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>